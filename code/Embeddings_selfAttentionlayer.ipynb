{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FullEndToEnd_selfAttentionlayer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBAv7pIdHVd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.1.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUUzfY-5HtjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3630e07-1244-4560-bbc8-3843bf3e7d40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr-esjugH2bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_DIR = \"/content/drive/Colab Notebooks/cleansed_data.csv\"\n",
        "DATA_FILE_NAME = 'Colab Notebooks/input_data.xlsx'\n",
        "CLEANSED_FILE_DIR = 'Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot67WsU5IA8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfPEX9ZQID36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding , Activation, Bidirectional, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VFwdpuTIFy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "  if(filename.endswith('.xlsx')):\n",
        "    data_df = pd.read_excel(filename, lines=True)\n",
        "  elif(filename.endswith('.csv')):\n",
        "    data_df = pd.read_csv(filename, keep_default_na = False,delimiter=',')\n",
        "  return data_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdIqnI5IIIAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_target(target):\n",
        "  le = LabelEncoder()\n",
        "  return le.fit_transform(target), le\n",
        "\n",
        "def decode_prediction(pred, encoder):\n",
        "  return encoder.inverse_transform(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrsfqprDIJf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ae0c61d-2438-4002-a775-4a42e82271c9"
      },
      "source": [
        "cleansed_data_df = load_doc(\"/content/drive/My Drive/Colab Notebooks/input.xlsx\")\n",
        "print('shape of Data : ', cleansed_data_df.shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of Data :  (8500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjfpNvRbIMji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c61f00f0-e84c-47f7-924e-e77fcfa9620a"
      },
      "source": [
        "cleansed_data_df.describe()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8492</td>\n",
              "      <td>8499</td>\n",
              "      <td>8500</td>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>7481</td>\n",
              "      <td>7817</td>\n",
              "      <td>2950</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>password reset</td>\n",
              "      <td>the</td>\n",
              "      <td>bpctwhsn kzqsbmtp</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>38</td>\n",
              "      <td>56</td>\n",
              "      <td>810</td>\n",
              "      <td>3976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Short description Description             Caller Assignment group\n",
              "count               8492        8499               8500             8500\n",
              "unique              7481        7817               2950               74\n",
              "top       password reset         the  bpctwhsn kzqsbmtp            GRP_0\n",
              "freq                  38          56                810             3976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htjp6TLQIfAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "1410ec58-4a51-4d66-f154-f481645b4df7"
      },
      "source": [
        "cleansed_data_df.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>-verified user details.(employee# &amp; manager na...</td>\n",
              "      <td>spxjnwir pjlcoqds</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n",
              "      <td>hmjdrvpb komuaywn</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log in to vpn</td>\n",
              "      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n",
              "      <td>eylqgodm ybqkwiam</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>xbkucsvz gcpydteq</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>owlgqjme qhcozdfx</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Short description  ... Assignment group\n",
              "0                    login issue  ...            GRP_0\n",
              "1                        outlook  ...            GRP_0\n",
              "2             cant log in to vpn  ...            GRP_0\n",
              "3  unable to access hr_tool page  ...            GRP_0\n",
              "4                   skype error   ...            GRP_0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT0wHo60IhKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data_df[\"Short description\"].fillna(\"The\", inplace=True)\n",
        "cleansed_data_df[\"Description\"].fillna(\"The\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTf22AEiIqzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data = cleansed_data_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zTnVq-kIs3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be92d5c8-17af-4e01-c24c-954793676f96"
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Toih1WIv0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punct(text):\n",
        "    text = re.sub('[0-9]+|\\n|\\r|[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', ' ', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS6lkSxWIyE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "cleansed_data['Description_new'] = cleansed_data['Description'].apply(lambda x: remove_punct(x))\n",
        "cleansed_data['Short description'] = cleansed_data['Short description'].apply(lambda x: remove_punct(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il29Ura9I0Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN5mgXyMI2qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0kgAtiPI4Yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e48f3a2f-871a-41d9-bfb0-42333e74c31d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L3bRwxlI6Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e94a55af-fdf6-4cf4-d2f9-2ca2f9b7ef20"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "print(stop_words)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'me', 'yours', 'didn', 'isn', 'a', 'those', 'about', \"you've\", \"aren't\", 'when', 'where', 'such', 'through', \"won't\", 'on', 'shouldn', 'am', 'been', 'weren', 'an', 'down', 't', 'ourselves', 'd', 'into', \"couldn't\", 'of', 'further', 'ours', 'our', 'under', 'here', 'then', 'if', 'don', 'who', 'theirs', 'whom', \"it's\", 'more', 'between', 'few', 'have', 'did', 'just', \"wouldn't\", 'all', 'for', 'you', 'off', \"doesn't\", 'herself', 'wouldn', 'doesn', 'nor', 'the', 'yourself', 'himself', 'won', \"weren't\", 'both', 'your', 'up', 'its', \"needn't\", 'now', 'them', \"you'd\", 'her', 'does', 'over', 'to', 're', \"hadn't\", 'was', 'as', 'wasn', 'below', 'and', 'no', \"shouldn't\", 'itself', 'or', 'haven', 'can', \"you're\", 'above', 'what', 'will', 'hadn', 'out', \"didn't\", 'has', 'why', 'this', 'at', 'before', 'so', 'i', 'hers', 'it', 'from', 'how', 'but', \"wasn't\", 'she', 'these', 'than', 'other', 'most', 'until', 'own', 'too', 'against', 'should', 'some', 'which', 'because', 'having', 'while', \"you'll\", 'that', 'after', 'him', 'they', 'were', 'doing', 'ma', 'mightn', \"don't\", 'm', 'needn', \"isn't\", 'there', 'mustn', \"that'll\", 'do', 'themselves', 's', 've', 'their', 'hasn', \"she's\", 'myself', 'his', 'any', 'very', 'once', \"hasn't\", 'we', 'couldn', 'aren', 'my', 'each', 'only', 'he', 'by', 'are', \"shan't\", 'not', 'being', 'ain', \"should've\", 'had', 'be', 'y', 'o', \"mightn't\", 'is', 'with', 'in', 'shan', \"haven't\", 'during', 'again', \"mustn't\", 'll', 'same', 'yourselves'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68f35iMuI-zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data['Description_new1'] = cleansed_data['Description_new'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "cleansed_data['Short description'] = cleansed_data['Short description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3nhB3qfI8lC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "22feeadb-f30f-4523-e552-b62db66e96c4"
      },
      "source": [
        "cleansed_data[['Description','Description_new','Description_new1']].head(10)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Description_new</th>\n",
              "      <th>Description_new1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-verified user details.(employee# &amp; manager na...</td>\n",
              "      <td>verified user details  employee    manager na...</td>\n",
              "      <td>verified user details employee manager name ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n",
              "      <td>received from  hmjdrvpb komuaywn gmail com...</td>\n",
              "      <td>received hmjdrvpb komuaywn gmail com hello tea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n",
              "      <td>received from  eylqgodm ybqkwiam gmail com...</td>\n",
              "      <td>received eylqgodm ybqkwiam gmail com hi cannot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>unable to access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>unable to log in to engineering tool and skype</td>\n",
              "      <td>unable to log in to engineering tool and skype</td>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>event: critical:HostName_221.company.com the v...</td>\n",
              "      <td>event  critical HostName   company com the val...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ticket_no1550391- employment status - new non-...</td>\n",
              "      <td>ticket no   employment status   new non employ...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>unable to disable add ins on outlook</td>\n",
              "      <td>unable to disable add ins on outlook</td>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ticket update on inplant_874773</td>\n",
              "      <td>ticket update on inplant</td>\n",
              "      <td>ticket update inplant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description  ...                                   Description_new1\n",
              "0  -verified user details.(employee# & manager na...  ...  verified user details employee manager name ch...\n",
              "1  \\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...  ...  received hmjdrvpb komuaywn gmail com hello tea...\n",
              "2  \\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...  ...  received eylqgodm ybqkwiam gmail com hi cannot...\n",
              "3                      unable to access hr_tool page  ...                         unable access hr tool page\n",
              "4                                       skype error   ...                                        skype error\n",
              "5     unable to log in to engineering tool and skype  ...                  unable log engineering tool skype\n",
              "6  event: critical:HostName_221.company.com the v...  ...  event critical HostName company com value moun...\n",
              "7  ticket_no1550391- employment status - new non-...  ...  ticket employment status new non employee ente...\n",
              "8               unable to disable add ins on outlook  ...                     unable disable add ins outlook\n",
              "9                    ticket update on inplant_874773  ...                              ticket update inplant\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHRJ9luKJBOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cleansed_data['Description'] = cleansed_data['Description_new1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmDzAjeEJDhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "text1 = \"THIS COMMUNICATION IS INTENDED FOR THE SOLE USE OF THE PERSON TO WHOM IT IS ADDRESSED AND MAY CONTAIN INFORMATION THAT IS PRIVILEGED, CONFIDENTIAL AND EXEMPT FROM DISCLOSURE UNDER APPLICABLE LAW. ANY DISSEMINATION, DISTRIBUTION OR DUPLICATION OF THIS COMMUNICATION BY SOMEONE OTHER THAN THE INTENDED RECIPIENT IS STRICTLY PROHIBITED. IF YOUR RECEIPT OF THIS COMMUNICATION IS IN ERROR, PLEASE NOTIFY THE SENDER AND DELETE THIS COMMUNICATION\"\n",
        "cleansed_data['Description'] = cleansed_data['Description'].apply(lambda x: re.sub(text1,'',x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpCc13cBJFTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2 = \"Select the following link to view the Disclaimer in an alternate language.\"\n",
        "cleansed_data['Description'] = cleansed_data['Description'].apply(lambda x: re.sub(text2,'',x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GZ40j6bKIvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data[\"SD - DD\"] = cleansed_data['Short description'].str.cat(cleansed_data[\"Description\"], sep= ' - ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zf8Q6PQJHfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "ab91a1ff-914e-4b9d-8421-485d4f9a8bdc"
      },
      "source": [
        "print(cleansed_data.columns)\n",
        "cleansed_data.head(10)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Short description', 'Description', 'Caller', 'Assignment group',\n",
            "       'Description_new', 'Description_new1', 'SD - DD'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>Description_new</th>\n",
              "      <th>Description_new1</th>\n",
              "      <th>SD - DD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verified user details employee manager name ch...</td>\n",
              "      <td>spxjnwir pjlcoqds</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>verified user details  employee    manager na...</td>\n",
              "      <td>verified user details employee manager name ch...</td>\n",
              "      <td>login issue - verified user details employee m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>received hmjdrvpb komuaywn gmail com hello tea...</td>\n",
              "      <td>hmjdrvpb komuaywn</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>received from  hmjdrvpb komuaywn gmail com...</td>\n",
              "      <td>received hmjdrvpb komuaywn gmail com hello tea...</td>\n",
              "      <td>outlook - received hmjdrvpb komuaywn gmail com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>received eylqgodm ybqkwiam gmail com hi cannot...</td>\n",
              "      <td>eylqgodm ybqkwiam</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>received from  eylqgodm ybqkwiam gmail com...</td>\n",
              "      <td>received eylqgodm ybqkwiam gmail com hi cannot...</td>\n",
              "      <td>cant log vpn - received eylqgodm ybqkwiam gmai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>xbkucsvz gcpydteq</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page - unable access hr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>owlgqjme qhcozdfx</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error - skype error</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "      <td>eflahbxn ltdgrvkz</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to log in to engineering tool and skype</td>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "      <td>unable log engineering tool skype - unable log...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "      <td>jyoqwxhz clhxsoqy</td>\n",
              "      <td>GRP_1</td>\n",
              "      <td>event  critical HostName   company com the val...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "      <td>eqzibjhw ymebpoih</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>ticket no   employment status   new non employ...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "      <td>mdbegvct dbvichlg</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to disable add ins on outlook</td>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "      <td>unable disable add ins outlook - unable disabl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ticket update inplant</td>\n",
              "      <td>ticket update inplant</td>\n",
              "      <td>fumkcsji sarmtlhy</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>ticket update on inplant</td>\n",
              "      <td>ticket update inplant</td>\n",
              "      <td>ticket update inplant - ticket update inplant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Short description  ...                                            SD - DD\n",
              "0                                        login issue  ...  login issue - verified user details employee m...\n",
              "1                                            outlook  ...  outlook - received hmjdrvpb komuaywn gmail com...\n",
              "2                                       cant log vpn  ...  cant log vpn - received eylqgodm ybqkwiam gmai...\n",
              "3                         unable access hr tool page  ...  unable access hr tool page - unable access hr ...\n",
              "4                                        skype error  ...                          skype error - skype error\n",
              "5                  unable log engineering tool skype  ...  unable log engineering tool skype - unable log...\n",
              "6  event critical HostName company com value moun...  ...  event critical HostName company com value moun...\n",
              "7  ticket employment status new non employee ente...  ...  ticket employment status new non employee ente...\n",
              "8                     unable disable add ins outlook  ...  unable disable add ins outlook - unable disabl...\n",
              "9                              ticket update inplant  ...      ticket update inplant - ticket update inplant\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS1BEgHmJKfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "cleansed_data['Assignment group'] = labelencoder.fit_transform(cleansed_data['Assignment group'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnsqixu1JNW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_count = cleansed_data['Assignment group'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ezqYrPUJO6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "485f216d-e6d1-4e0e-bfef-3f7e11973bf4"
      },
      "source": [
        "\n",
        "(target_count<=10).value_counts()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    49\n",
              "True     25\n",
              "Name: Assignment group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgjosEgMJUic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "c24f50d0-fc52-46f3-fb10-480c7649fb9c"
      },
      "source": [
        "oneHotencoder = OneHotEncoder()\n",
        "\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = oneHotencoder.fit_transform(cleansed_data['Assignment group'].values.reshape(-1,1)).toarray()\n",
        "print(X)\n",
        "#print(cleansed_data.shape[1])\n",
        "#To add this back into the original dataframe \n",
        "#dfOneHot = pd.DataFrame(X, columns = [\"assignment_group_\"+str(int(i)) for i in range(cleansed_data.shape[1])]) \n",
        "#df = pd.concat([cleansed_data, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "#df= df.drop(['assignment_group'], axis=1) \n",
        "#printing to verify \n",
        "#print(df.head())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Q_PBKDJp9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train_keras, x_test_keras, y_train_keras, y_test_keras = train_test_split(cleansed_data['SD - DD'], X, test_size=0.15, shuffle= True)\n",
        "x_train_keras, x_valid_keras, y_train_keras, y_valid_keras = train_test_split(x_train_keras, y_train_keras, test_size=0.15, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-cBkSmaJsgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e058002b-aa77-4764-9dd9-b07b1fb0bae9"
      },
      "source": [
        "print(x_train_keras.shape)\n",
        "print(x_valid_keras.shape)\n",
        "print(x_test_keras.shape)\n",
        "print(y_train_keras.shape)\n",
        "print(y_valid_keras.shape)\n",
        "print(y_test_keras.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6141,)\n",
            "(1084,)\n",
            "(1275,)\n",
            "(6141, 74)\n",
            "(1084, 74)\n",
            "(1275, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6rKBLDLKkwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3KUsZxlKm2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 10000\n",
        "# finally, vectorize the text samples into a 2D integer tensor\n",
        "tokenizer = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenizer.fit_on_texts(x_train_keras)\n",
        "sequences_train = tokenizer.texts_to_sequences(x_train_keras)\n",
        "sequences_valid = tokenizer.texts_to_sequences(x_valid_keras)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffUmEILKKqKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "79b98305-db5b-4cac-e13d-8e7233429bfe"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 150\n",
        "\n",
        "# pad sequences with 0s\n",
        "X_train = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_valid = pad_sequences(sequences_valid, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_train.shape)\n",
        "print('Shape of data test tensor:', X_test.shape)\n",
        "print('Shape of data validation tensor:', X_valid.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (6141, 150)\n",
            "Shape of data test tensor: (1275, 150)\n",
            "Shape of data validation tensor: (1084, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ayj4q9Kw1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a043c00-5c0b-4c62-e117-95822ff95e7c"
      },
      "source": [
        "type(x_train_keras)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klC1DrreKzyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "21cda20d-36c9-4665-cc90-f7920774f10f"
      },
      "source": [
        "x_train_keras.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1987    reset passwords jvpkulxw ovuweygj using passwo...\n",
              "5446                ad account locked - ad account locked\n",
              "5347    network outage turkey turkey site hard since e...\n",
              "4397    vip printer driver update - vip printer driver...\n",
              "2675    cannot access \\\\HostName \\engineering applicat...\n",
              "Name: SD - DD, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PG8IEI5K2KW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28ddd960-eed6-4bba-eb62-287944487f19"
      },
      "source": [
        "X_train[0:6]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,   15,  168,\n",
              "        2136, 2137,   95,    6,   90,    4,    6,   15,   15,  168, 2136,\n",
              "        2137,   95,    6,   90,    4,    6,   15],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  176,   21,   42,  176,   21,   42],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,   39,   64, 2363, 2363,   32,  585,\n",
              "          78,   69,   67,   64,   45,   39,   38,   40,    8,  246,   67,\n",
              "          64,  214,  115,   32, 1820,   10,   11,  124,   69,  110,  107,\n",
              "          40,   10,   11,    3,   40,  118,   40,  110,  107,   39,   10,\n",
              "          11,    3,  121,   10,  118,  121,   22,   32,   54,   38,   10,\n",
              "          10,   11,   54,   38,  155,   10,   11,   32,   98,  119,   63,\n",
              "          29,   10,   11,  154,  240,   11,   10,   11,  243,   15,   11,\n",
              "          10,   11,  184,   32,   30,   54,   38,   11,   10,   11,   44,\n",
              "          22,  136,   59,  251,   59,   44,   59,   44,  119,  187,   10,\n",
              "          11,  115,  200,   10,   11,  206,  252],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  353,\n",
              "          65,  400,   46,  353,   65,  400,   46],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,   83,   18,   27,   50,  175,   47,    3,   95, 7676,  151,\n",
              "         980,  775,   83,   18,   27,   50,  175,   47,    3,   95, 3775,\n",
              "         151,  980,  775,    8,  521, 7677,  127, 7678,   18,   27,   50,\n",
              "         175,   95,  336, 7679, 4783, 1085, 1086,  127,  713, 3775,  336,\n",
              "         127,  188, 4783,  336,   47,  713,  113, 3775, 7680,   47, 7681,\n",
              "          18,  495,   27,   27,   83,   18,   27],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0, 1691,   24,    5, 3776, 3777,    7,\n",
              "           2,  161,  199,    8,   33,  133,  324, 1691,  194,  938,  401,\n",
              "        7682,   61,   51,  125, 1582, 1692,   23]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vpfa2sqLBvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c485980f-9d2d-4f48-9837-ff5f24bb3027"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('../content/drive/My Drive/Colab Notebooks/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3pcDdgLLHow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0d16dbf-a581-45c6-8dc5-edbdebc90a34"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82_6ahTqLPNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((size_of_vocabulary, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DITzhuaELYrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, Flatten, BatchNormalization, Dropout\n",
        "from keras.layers import GlobalAveragePooling1D, Embedding, LSTM, Bidirectional\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4pfFQRgLa5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "e75db0d9-997a-47ef-8007-27242d920f70"
      },
      "source": [
        "pip install keras_self_attention"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_self_attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (1.18.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P01IFgCLc5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_self_attention import SeqSelfAttention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6tZa9ilLfyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "#embedding layer\n",
        "#model.add(Input(shape=(150,)))\n",
        "model.add(Embedding(size_of_vocabulary,100,weights=[embedding_matrix],input_length=150,trainable=True)) \n",
        "\n",
        "#Bilstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2,recurrent_dropout=0.2)))\n",
        "model.add(SeqSelfAttention(units = 32, attention_activation='relu'))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "#model.add(Dense(256,activation='relu'))  \n",
        "#model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "rlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=0, mode=\"auto\", min_delta=0.0001, cooldown=0)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SPA2BzPLk1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "37bdb1c4-96cb-49fb-fa1c-cfc9bcc1ff06"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 150, 100)          1311500   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 150, 256)          234496    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_2 (SeqSel (None, 150, 256)          16449     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 38400)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 74)                2841674   \n",
            "=================================================================\n",
            "Total params: 4,404,119\n",
            "Trainable params: 4,404,119\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4DYrsQ3L2vA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f28d03c2-7e1f-430f-c037-f7a8a855ff88"
      },
      "source": [
        "historical = model.fit(X_train,y_train_keras,batch_size=32,epochs=50,validation_data=(X_valid,y_valid_keras),verbose=1,callbacks=[es,rlr,mc])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6141 samples, validate on 1084 samples\n",
            "Epoch 1/50\n",
            "6141/6141 [==============================] - 144s 23ms/step - loss: 2.1148 - acc: 0.5375 - val_loss: 1.6067 - val_acc: 0.6255\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.62546, saving model to best_model.h5\n",
            "Epoch 2/50\n",
            "6141/6141 [==============================] - 145s 24ms/step - loss: 1.5421 - acc: 0.6124 - val_loss: 1.3784 - val_acc: 0.6568\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.62546 to 0.65683, saving model to best_model.h5\n",
            "Epoch 3/50\n",
            "6141/6141 [==============================] - 140s 23ms/step - loss: 1.2566 - acc: 0.6606 - val_loss: 1.2877 - val_acc: 0.6688\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.65683 to 0.66882, saving model to best_model.h5\n",
            "Epoch 4/50\n",
            "6141/6141 [==============================] - 140s 23ms/step - loss: 1.0173 - acc: 0.7154 - val_loss: 1.3372 - val_acc: 0.6780\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66882 to 0.67804, saving model to best_model.h5\n",
            "Epoch 5/50\n",
            "6141/6141 [==============================] - 139s 23ms/step - loss: 0.8061 - acc: 0.7673 - val_loss: 1.4148 - val_acc: 0.6651\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67804\n",
            "Epoch 6/50\n",
            "6141/6141 [==============================] - 142s 23ms/step - loss: 0.6250 - acc: 0.8127 - val_loss: 1.4577 - val_acc: 0.6716\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67804\n",
            "Epoch 7/50\n",
            "6141/6141 [==============================] - 141s 23ms/step - loss: 0.4240 - acc: 0.8701 - val_loss: 1.4944 - val_acc: 0.6790\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.67804 to 0.67897, saving model to best_model.h5\n",
            "Epoch 8/50\n",
            "6141/6141 [==============================] - 139s 23ms/step - loss: 0.3770 - acc: 0.8801 - val_loss: 1.5159 - val_acc: 0.6790\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.67897\n",
            "Epoch 9/50\n",
            "6141/6141 [==============================] - 133s 22ms/step - loss: 0.3639 - acc: 0.8811 - val_loss: 1.5534 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.67897 to 0.68542, saving model to best_model.h5\n",
            "Epoch 10/50\n",
            "6141/6141 [==============================] - 136s 22ms/step - loss: 0.3306 - acc: 0.8919 - val_loss: 1.5565 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.68542 to 0.68635, saving model to best_model.h5\n",
            "Epoch 11/50\n",
            "6141/6141 [==============================] - 133s 22ms/step - loss: 0.3381 - acc: 0.8915 - val_loss: 1.5603 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.68635\n",
            "Epoch 12/50\n",
            "6141/6141 [==============================] - 133s 22ms/step - loss: 0.3261 - acc: 0.8948 - val_loss: 1.5633 - val_acc: 0.6873\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.68635 to 0.68727, saving model to best_model.h5\n",
            "Epoch 13/50\n",
            "6141/6141 [==============================] - 132s 22ms/step - loss: 0.3338 - acc: 0.8929 - val_loss: 1.5631 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.68727\n",
            "Epoch 14/50\n",
            "6141/6141 [==============================] - 130s 21ms/step - loss: 0.3368 - acc: 0.8907 - val_loss: 1.5632 - val_acc: 0.6873\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.68727\n",
            "Epoch 15/50\n",
            "6141/6141 [==============================] - 130s 21ms/step - loss: 0.3303 - acc: 0.8971 - val_loss: 1.5637 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.68727\n",
            "Epoch 16/50\n",
            "6141/6141 [==============================] - 124s 20ms/step - loss: 0.3338 - acc: 0.8919 - val_loss: 1.5637 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.68727\n",
            "Epoch 17/50\n",
            "6141/6141 [==============================] - 135s 22ms/step - loss: 0.3316 - acc: 0.8911 - val_loss: 1.5637 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.68727\n",
            "Epoch 18/50\n",
            "6141/6141 [==============================] - 133s 22ms/step - loss: 0.3305 - acc: 0.8943 - val_loss: 1.5637 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.68727\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNZ6SSAGdT8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train_vec, x_test_vec, y_train_vec, y_test_vec = train_test_split(cleansed_data['SD - DD'], X, test_size=0.15, shuffle= True)\n",
        "x_train_vec, x_valid_vec, y_train_vec, y_valid_vec = train_test_split(x_train_vec, y_train_vec, test_size=0.15, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RD74IriM5ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f673e29c-e2ea-4428-94ab-230a98f76bea"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train_vec)\n",
        "y_test_cate = to_categorical(y_train_vec)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train_vec = x_train_vec.astype(str)\n",
        "x_valid_vec = x_valid_vec.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(x_train_vec)\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq_vec  = tokenizer.texts_to_sequences(x_train_vec) \n",
        "x_val_seq_vec = tokenizer.texts_to_sequences(x_valid_vec)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq_vec  = pad_sequences(x_tr_seq_vec, maxlen=200)\n",
        "x_val_seq_vec = pad_sequences(x_val_seq_vec, maxlen=200)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6141, 74, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinBbXwPNf_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd02dd0b-60f4-4155-f876-158bcd4ffafa"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crITMtIJOAsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "PROJECT_DIR = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "EMBEDDING_FILE = 'SO_vectors_200.bin'\n",
        "EmbeddingFile = PROJECT_DIR+EMBEDDING_FILE\n",
        "word2vec = KeyedVectors.load_word2vec_format(EmbeddingFile, binary=True)\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "MAX_NB_WORDS = 200000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWSR69LKOFbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "EMBEDDING_DIM = 200\n",
        "embedding_matrix_word2vec = np.zeros((size_of_vocabulary, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embedding_matrix_word2vec[i] = word2vec.word_vec(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYLADS4JOJN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "#embedding layer\n",
        "#model.add(Input(shape=(150,)))\n",
        "model.add(Embedding(size_of_vocabulary,200,weights=[embedding_matrix_word2vec],input_length=200,trainable=True)) \n",
        "\n",
        "#Bilstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2,recurrent_dropout=0.2)))\n",
        "model.add(SeqSelfAttention(units = 32, attention_activation='relu'))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "#model.add(Dense(256,activation='relu'))  \n",
        "#model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "rlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=0, mode=\"auto\", min_delta=0.0001, cooldown=0)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZwN7VY1nmc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "b1b727c6-0b5f-45f1-90da-0783eee0bfc8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 200, 200)          2655000   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 200, 256)          336896    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_3 (SeqSel (None, 200, 256)          16449     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 74)                3788874   \n",
            "=================================================================\n",
            "Total params: 6,797,219\n",
            "Trainable params: 6,797,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YeOwbriOPyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "981a55b8-1db6-461d-94a1-d35fd89d2f9e"
      },
      "source": [
        "history = model.fit(x_tr_seq_vec,y_train_vec,batch_size=32,epochs=50,validation_data=(x_val_seq_vec,y_valid_vec),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6141 samples, validate on 1084 samples\n",
            "Epoch 1/50\n",
            "6141/6141 [==============================] - 235s 38ms/step - loss: 1.9436 - acc: 0.5620 - val_loss: 1.4913 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.62731, saving model to best_model.h5\n",
            "Epoch 2/50\n",
            "6141/6141 [==============================] - 232s 38ms/step - loss: 1.4074 - acc: 0.6341 - val_loss: 1.4616 - val_acc: 0.6541\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.62731 to 0.65406, saving model to best_model.h5\n",
            "Epoch 3/50\n",
            "6141/6141 [==============================] - 232s 38ms/step - loss: 1.1004 - acc: 0.7002 - val_loss: 1.4972 - val_acc: 0.6494\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.65406\n",
            "Epoch 4/50\n",
            "6141/6141 [==============================] - 233s 38ms/step - loss: 0.8335 - acc: 0.7522 - val_loss: 1.4762 - val_acc: 0.6762\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.65406 to 0.67620, saving model to best_model.h5\n",
            "Epoch 5/50\n",
            "6141/6141 [==============================] - 232s 38ms/step - loss: 0.6409 - acc: 0.8096 - val_loss: 1.5459 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.67620 to 0.68542, saving model to best_model.h5\n",
            "Epoch 6/50\n",
            "6141/6141 [==============================] - 232s 38ms/step - loss: 0.4913 - acc: 0.8505 - val_loss: 1.6221 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.68542 to 0.69557, saving model to best_model.h5\n",
            "Epoch 7/50\n",
            "6141/6141 [==============================] - 233s 38ms/step - loss: 0.4331 - acc: 0.8705 - val_loss: 1.7550 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.69557\n",
            "Epoch 8/50\n",
            "6141/6141 [==============================] - 228s 37ms/step - loss: 0.3628 - acc: 0.8854 - val_loss: 1.8230 - val_acc: 0.6910\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.69557\n",
            "Epoch 9/50\n",
            "6141/6141 [==============================] - 226s 37ms/step - loss: 0.3384 - acc: 0.8914 - val_loss: 1.8453 - val_acc: 0.6762\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.69557\n",
            "Epoch 10/50\n",
            "6141/6141 [==============================] - 228s 37ms/step - loss: 0.2980 - acc: 0.9077 - val_loss: 1.9435 - val_acc: 0.6965\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.69557 to 0.69649, saving model to best_model.h5\n",
            "Epoch 11/50\n",
            "6141/6141 [==============================] - 224s 36ms/step - loss: 0.2695 - acc: 0.9174 - val_loss: 1.9681 - val_acc: 0.7048\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.69649 to 0.70480, saving model to best_model.h5\n",
            "Epoch 12/50\n",
            "6141/6141 [==============================] - 224s 36ms/step - loss: 0.2638 - acc: 0.9174 - val_loss: 2.1600 - val_acc: 0.6753\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.70480\n",
            "Epoch 13/50\n",
            "6141/6141 [==============================] - 226s 37ms/step - loss: 0.2700 - acc: 0.9165 - val_loss: 2.0673 - val_acc: 0.6780\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.70480\n",
            "Epoch 14/50\n",
            "6141/6141 [==============================] - 224s 36ms/step - loss: 0.2266 - acc: 0.9266 - val_loss: 2.0326 - val_acc: 0.6753\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.70480\n",
            "Epoch 15/50\n",
            "6141/6141 [==============================] - 223s 36ms/step - loss: 0.2482 - acc: 0.9233 - val_loss: 2.0000 - val_acc: 0.6946\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.70480\n",
            "Epoch 16/50\n",
            "6141/6141 [==============================] - 229s 37ms/step - loss: 0.2225 - acc: 0.9298 - val_loss: 2.4545 - val_acc: 0.6900\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.70480\n",
            "Epoch 17/50\n",
            "6141/6141 [==============================] - 226s 37ms/step - loss: 0.2353 - acc: 0.9243 - val_loss: 2.3045 - val_acc: 0.7048\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.70480\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0VhUfzC-7UF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train_fast, x_test_fast, y_train_fast, y_test_fast = train_test_split(cleansed_data['SD - DD'], X, test_size=0.15, shuffle= True)\n",
        "x_train_fast, x_valid_fast, y_train_fast, y_valid_fast = train_test_split(x_train_fast, y_train_fast, test_size=0.15, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6pNC9wYA_-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "04b62796-1b81-41ee-c9cb-69304f94a16e"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train_fast)\n",
        "y_test_cate = to_categorical(y_valid_fast)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train_fast = x_train_fast.astype(str)\n",
        "x_valid_fast = x_valid_fast.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(list(x_train_fast))\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq_fast  = tokenizer.texts_to_sequences(x_train_fast) \n",
        "x_val_seq_fast = tokenizer.texts_to_sequences(x_valid_fast)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq_fast  = pad_sequences(x_tr_seq_fast, maxlen=300)\n",
        "x_val_seq_fast = pad_sequences(x_val_seq_fast, maxlen=300)\n",
        "\n",
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6141, 74, 2)\n",
            "13218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QErgT56HBE8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 200000 #17780 #using all unique words\n",
        "embedding_dim = 300\n",
        "num_classes = 74\n",
        "batch_size = 32\n",
        "\n",
        "embedding_path = \"/content/drive/My Drive/Colab Notebooks/wiki-news-300d-1M.vec\"\n",
        "\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = len(word_index)\n",
        "embedding_matrix_fast = np.zeros((nb_words + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix_fast[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tVERnkEBNI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "#embedding layer\n",
        "#model.add(Input(shape=(150,)))\n",
        "model.add(Embedding(size_of_vocabulary,300,weights=[embedding_matrix_fast],input_length=300,trainable=True)) \n",
        "\n",
        "#Bilstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2,recurrent_dropout=0.2)))\n",
        "model.add(SeqSelfAttention(units = 32, attention_activation='relu'))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "#model.add(Dense(256,activation='relu'))  \n",
        "#model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "rlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=0, mode=\"auto\", min_delta=0.0001, cooldown=0)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh8Bmg2VJNkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "0a541358-1fde-4ee2-c841-660bcf72fb03"
      },
      "source": [
        "history = model.fit(x_tr_seq_fast,y_train_fast,batch_size=32,epochs=10,validation_data=(x_val_seq_fast,y_valid_fast),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6141 samples, validate on 1084 samples\n",
            "Epoch 1/10\n",
            "6141/6141 [==============================] - 404s 66ms/step - loss: 0.1954 - acc: 0.9360 - val_loss: 2.5173 - val_acc: 0.6614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.67528\n",
            "Epoch 2/10\n",
            "6141/6141 [==============================] - 405s 66ms/step - loss: 0.2100 - acc: 0.9334 - val_loss: 2.7515 - val_acc: 0.6513\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.67528\n",
            "Epoch 3/10\n",
            "6141/6141 [==============================] - 407s 66ms/step - loss: 0.2172 - acc: 0.9306 - val_loss: 2.6633 - val_acc: 0.6568\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67528\n",
            "Epoch 4/10\n",
            "6141/6141 [==============================] - 409s 67ms/step - loss: 0.2193 - acc: 0.9316 - val_loss: 3.0527 - val_acc: 0.6577\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67528\n",
            "Epoch 5/10\n",
            "6141/6141 [==============================] - 412s 67ms/step - loss: 0.2049 - acc: 0.9314 - val_loss: 3.0461 - val_acc: 0.6411\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67528\n",
            "Epoch 6/10\n",
            "6141/6141 [==============================] - 414s 67ms/step - loss: 0.2096 - acc: 0.9316 - val_loss: 3.0031 - val_acc: 0.6559\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67528\n",
            "Epoch 7/10\n",
            "6141/6141 [==============================] - 414s 67ms/step - loss: 0.1907 - acc: 0.9389 - val_loss: 2.7745 - val_acc: 0.6633\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.67528\n",
            "Epoch 8/10\n",
            "6141/6141 [==============================] - 413s 67ms/step - loss: 0.1816 - acc: 0.9419 - val_loss: 3.1309 - val_acc: 0.6227\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.67528\n",
            "Epoch 9/10\n",
            "6141/6141 [==============================] - 409s 67ms/step - loss: 0.1720 - acc: 0.9425 - val_loss: 3.2233 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.67528\n",
            "Epoch 10/10\n",
            "6141/6141 [==============================] - 411s 67ms/step - loss: 0.1918 - acc: 0.9397 - val_loss: 3.0414 - val_acc: 0.6292\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.67528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRtSGxIXdSwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "ce53140d-0822-47a8-dc21-5d908b2ae217"
      },
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,val_acc = model.evaluate(x_val_seq_fast,y_valid_fast, batch_size=32)\n",
        "print(val_acc)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-fe276c106f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loading best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    625\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             layer = layer_module.deserialize(conf,\n\u001b[0;32m--> 301\u001b[0;31m                                              custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 140\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: SeqSelfAttention"
          ]
        }
      ]
    }
  ]
}