{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQNehRykEju9"
   },
   "outputs": [],
   "source": [
    "#!!pip uninstall tensorflow\n",
    "#!pip install tensorflow==2.1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "KTEsLA0vF0TE",
    "outputId": "0e318bb9-2f08-4b1d-934d-8e19c796c46c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hogv62O1F2tM"
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = \"/content/drive/My Drive/Colab Notebooks/cleansed_data.csv\"\n",
    "DATA_FILE_NAME = 'My Drive/Colab Notebooks/input.xlsx'\n",
    "CLEANSED_FILE_DIR = '/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Uv4c072H8ok"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Crcb7k6-IGbL"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Activation, Bidirectional, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQpKMRAcIZo6"
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "  if(filename.endswith('.xlsx')):\n",
    "    data_df = pd.read_excel(filename, lines=True)\n",
    "  elif(filename.endswith('.csv')):\n",
    "    data_df = pd.read_csv(filename, keep_default_na = False)\n",
    "  return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CoyNMVRIdYk"
   },
   "outputs": [],
   "source": [
    "def encode_target(target):\n",
    "  le = LabelEncoder()\n",
    "  return le.fit_transform(target), le\n",
    "\n",
    "def decode_prediction(pred, encoder):\n",
    "  return encoder.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uPbVspqMIiu4",
    "outputId": "95334d0b-5dbf-430f-f9e3-d175ef321245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Data :  (8500, 4)\n"
     ]
    }
   ],
   "source": [
    "cleansed_data_df = load_doc(PROJECT_DIR)\n",
    "print('shape of Data : ', cleansed_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "cPtAl6Q5Izji",
    "outputId": "135eb13e-3ebf-481f-c86e-5282cc014d57"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>description</th>\n",
       "      <th>combined_desc</th>\n",
       "      <th>assignment_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8500</td>\n",
       "      <td>8500</td>\n",
       "      <td>8500</td>\n",
       "      <td>8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6000</td>\n",
       "      <td>5484</td>\n",
       "      <td>5634</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>job job failed job scheduler</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GRP_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>473</td>\n",
       "      <td>1123</td>\n",
       "      <td>1047</td>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   short_description description combined_desc assignment_group\n",
       "count                           8500        8500          8500             8500\n",
       "unique                          6000        5484          5634               74\n",
       "top     job job failed job scheduler                                      GRP_0\n",
       "freq                             473        1123          1047             3976"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "M5rlps6XI6sC",
    "outputId": "391c4875-568e-471a-88c8-a2e198ac08a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>description</th>\n",
       "      <th>combined_desc</th>\n",
       "      <th>assignment_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>login issue</td>\n",
       "      <td>verified user details employee manager checked...</td>\n",
       "      <td>login issue verified user details employee man...</td>\n",
       "      <td>GRP_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlook</td>\n",
       "      <td>team meetings skype meetings etc not appearing...</td>\n",
       "      <td>outlook team meetings skype meetings etc not a...</td>\n",
       "      <td>GRP_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cant log vpn</td>\n",
       "      <td>hi cannot log vpn</td>\n",
       "      <td>cant log vpn hi cannot log vpn</td>\n",
       "      <td>GRP_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>unable access hr tool page unable access hr to...</td>\n",
       "      <td>GRP_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skype error</td>\n",
       "      <td>skype error</td>\n",
       "      <td>skype error skype error</td>\n",
       "      <td>GRP_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            short_description  ... assignment_group\n",
       "0                 login issue  ...            GRP_0\n",
       "1                     outlook  ...            GRP_0\n",
       "2                cant log vpn  ...            GRP_0\n",
       "3  unable access hr tool page  ...            GRP_0\n",
       "4                 skype error  ...            GRP_0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ol7yVaf6JKYZ"
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "cleansed_data_df['assignment_group'] = labelencoder.fit_transform(cleansed_data_df['assignment_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "-GS9RJGiJUyp",
    "outputId": "7da8b154-797e-48d8-95d0-1d9ebce9e3b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>description</th>\n",
       "      <th>combined_desc</th>\n",
       "      <th>assignment_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>login issue</td>\n",
       "      <td>verified user details employee manager checked...</td>\n",
       "      <td>login issue verified user details employee man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlook</td>\n",
       "      <td>team meetings skype meetings etc not appearing...</td>\n",
       "      <td>outlook team meetings skype meetings etc not a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cant log vpn</td>\n",
       "      <td>hi cannot log vpn</td>\n",
       "      <td>cant log vpn hi cannot log vpn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>unable access hr tool page unable access hr to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skype error</td>\n",
       "      <td>skype error</td>\n",
       "      <td>skype error skype error</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>emails not coming zz mail</td>\n",
       "      <td>good afternoon not receiving emails sent zz ma...</td>\n",
       "      <td>emails not coming zz mail good afternoon not r...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>telephony software issue</td>\n",
       "      <td>telephony software issue</td>\n",
       "      <td>telephony software issue telephony software issue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>windows password reset tifpdchb pedxruyf</td>\n",
       "      <td>windows password reset tifpdchb pedxruyf</td>\n",
       "      <td>windows password reset tifpdchb pedxruyf windo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>machine funcionando</td>\n",
       "      <td>unable access machine utilities finish drawers...</td>\n",
       "      <td>machine funcionando unable access machine util...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>mehreren pc lassen sich verschiedene prgramdnt...</td>\n",
       "      <td>mehreren pc lassen sich verschiedene prgramdnt...</td>\n",
       "      <td>mehreren pc lassen sich verschiedene prgramdnt...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      short_description  ... assignment_group\n",
       "0                                           login issue  ...                0\n",
       "1                                               outlook  ...                0\n",
       "2                                          cant log vpn  ...                0\n",
       "3                            unable access hr tool page  ...                0\n",
       "4                                           skype error  ...                0\n",
       "...                                                 ...  ...              ...\n",
       "8495                          emails not coming zz mail  ...               22\n",
       "8496                           telephony software issue  ...                0\n",
       "8497           windows password reset tifpdchb pedxruyf  ...                0\n",
       "8498                                machine funcionando  ...               59\n",
       "8499  mehreren pc lassen sich verschiedene prgramdnt...  ...               44\n",
       "\n",
       "[8500 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleansed_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgctIXGgX5Xe"
   },
   "outputs": [],
   "source": [
    "cleansed_data = cleansed_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "trqdBJKYSi_S",
    "outputId": "2ebe443b-3d23-44ed-c0fd-9d39a083f354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "oneHotencoder = OneHotEncoder()\n",
    "\n",
    "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
    "X = oneHotencoder.fit_transform(cleansed_data['assignment_group'].values.reshape(-1,1)).toarray()\n",
    "print(X)\n",
    "#print(cleansed_data.shape[1])\n",
    "#To add this back into the original dataframe \n",
    "#dfOneHot = pd.DataFrame(X, columns = [\"assignment_group_\"+str(int(i)) for i in range(cleansed_data.shape[1])]) \n",
    "#df = pd.concat([cleansed_data, dfOneHot], axis=1)\n",
    "#droping the country column \n",
    "#df= df.drop(['assignment_group'], axis=1) \n",
    "#printing to verify \n",
    "#print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkVWGqu5JzgC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(cleansed_data_df['combined_desc'], X, test_size=0.2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "gp86EDeLJ-oG",
    "outputId": "68bc32e3-e067-4fa1-dae3-c8d640bc5293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pp5K1mCmKFNy",
    "outputId": "28663fc4-1df1-4b9f-ce01-2a83e15d3f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable connect vpn unable connect vpn\n"
     ]
    }
   ],
   "source": [
    "print(x_train[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qb34e6QXKI0h",
    "outputId": "fdc7cecb-dbc6-4ab4-c09b-1b7cb5306a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 74, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_train_cate = to_categorical(y_train)\n",
    "y_test_cate = to_categorical(y_valid)\n",
    "print(y_train_cate.shape)\n",
    "\n",
    "x_train = x_train.astype(str)\n",
    "x_valid = x_valid.astype(str)\n",
    "\n",
    "#Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
    "\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq  = tokenizer.texts_to_sequences(x_train) \n",
    "x_val_seq = tokenizer.texts_to_sequences(x_valid)\n",
    "\n",
    "#padding to prepare sequences of same length\n",
    "x_tr_seq  = pad_sequences(x_tr_seq, maxlen=200)\n",
    "x_val_seq = pad_sequences(x_val_seq, maxlen=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "L6RYIWcDKOJ5",
    "outputId": "352822fd-ca2e-4d4b-b9c4-68dfa071db02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vpn not working im not able connect company network vpn pls check cc sir not able upload result no company network\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  808   92 2660   43\n",
      "  808   92 2660   43]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[24])\n",
    "print(x_tr_seq[24])\n",
    "#print(x_train[24])\n",
    "#print(x_tr_seq[22])\n",
    "#print(x_tr_seq[24])\n",
    "#print(x_tr_seq[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aJcRpF_0LHDo",
    "outputId": "27429443-8380-4ca5-d7a8-63daabda8a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 74)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "print(y_train.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNL3-jr6LKTJ"
   },
   "source": [
    "**Pretrained Glove embeddings with 100d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xS7Hele3LPxp",
    "outputId": "6d2c5d59-2222-45c4-ee9e-66cda33bc14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('../content/drive/My Drive/Colab Notebooks/glove.6B.100d.txt')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SUc6K4O7LeZy",
    "outputId": "1848e6f5-c30d-4187-ba23-a979381bb428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8730\n"
     ]
    }
   ],
   "source": [
    "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH56rLNhLgws"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((size_of_vocabulary, 100))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnVRGWM6LldI"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "8V9tO3SNLoXy",
    "outputId": "f44f16bd-6819-4c24-812d-0be0f5bfe64e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 200, 100)          873000    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 200, 256)          234496    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 74)                9546      \n",
      "=================================================================\n",
      "Total params: 1,149,938\n",
      "Trainable params: 1,149,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,100,weights=[embedding_matrix],input_length=200,trainable=True)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dense(74,activation='softmax'))  \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"acc\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "JH0-vujqLqRy",
    "outputId": "f8a24ab0-fe5b-461a-9848-957e78321f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1700 samples\n",
      "Epoch 1/10\n",
      "6800/6800 [==============================] - 123s 18ms/step - loss: 2.2670 - acc: 0.5249 - val_loss: 1.8869 - val_acc: 0.5576\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.55765, saving model to best_model.h5\n",
      "Epoch 2/10\n",
      "6800/6800 [==============================] - 118s 17ms/step - loss: 1.7299 - acc: 0.5829 - val_loss: 1.6837 - val_acc: 0.6041\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.55765 to 0.60412, saving model to best_model.h5\n",
      "Epoch 3/10\n",
      "6800/6800 [==============================] - 118s 17ms/step - loss: 1.5121 - acc: 0.6247 - val_loss: 1.5758 - val_acc: 0.6118\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60412 to 0.61176, saving model to best_model.h5\n",
      "Epoch 4/10\n",
      "6800/6800 [==============================] - 118s 17ms/step - loss: 1.3534 - acc: 0.6509 - val_loss: 1.4970 - val_acc: 0.6224\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61176 to 0.62235, saving model to best_model.h5\n",
      "Epoch 5/10\n",
      "6800/6800 [==============================] - 118s 17ms/step - loss: 1.2051 - acc: 0.6822 - val_loss: 1.4648 - val_acc: 0.6241\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.62235 to 0.62412, saving model to best_model.h5\n",
      "Epoch 6/10\n",
      "6800/6800 [==============================] - 122s 18ms/step - loss: 1.0847 - acc: 0.7165 - val_loss: 1.4506 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.62412 to 0.64353, saving model to best_model.h5\n",
      "Epoch 7/10\n",
      "6800/6800 [==============================] - 118s 17ms/step - loss: 0.9739 - acc: 0.7449 - val_loss: 1.4814 - val_acc: 0.6376\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.64353\n",
      "Epoch 8/10\n",
      "6800/6800 [==============================] - 119s 17ms/step - loss: 0.8700 - acc: 0.7706 - val_loss: 1.5086 - val_acc: 0.6359\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.64353\n",
      "Epoch 9/10\n",
      "6800/6800 [==============================] - 118s 17ms/step - loss: 0.7971 - acc: 0.7849 - val_loss: 1.5495 - val_acc: 0.6329\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.64353\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr_seq,y_train,batch_size=32,epochs=10,validation_data=(x_val_seq,y_valid),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "56KLpw8rLuRy",
    "outputId": "7025bee5-765c-4b8c-8711-0c2bc32c02c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 5s 3ms/step\n",
      "0.6435294151306152\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "#evaluation \n",
    "_,val_acc = model.evaluate(x_val_seq,y_valid, batch_size=32)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "QSR5vYPPLyhy",
    "outputId": "1d3f22e0-e75b-4cbf-cc01-c5c87d53752f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (1.13.3)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (1.16.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaT8Do6_L0mg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "x_train_vec, x_valid_vec, y_train_vec, y_valid_vec = train_test_split(cleansed_data_df['combined_desc'], X, test_size=0.2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "al02LNwqPQkM",
    "outputId": "f7db8391-6139-426f-ca82-7c58b4efb9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 74, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_cate = to_categorical(y_train_vec)\n",
    "y_test_cate = to_categorical(y_train_vec)\n",
    "print(y_train_cate.shape)\n",
    "\n",
    "x_train_vec = x_train_vec.astype(str)\n",
    "x_valid_vec = x_valid_vec.astype(str)\n",
    "\n",
    "#Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(x_train_vec)\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq_vec  = tokenizer.texts_to_sequences(x_train_vec) \n",
    "x_val_seq_vec = tokenizer.texts_to_sequences(x_valid_vec)\n",
    "\n",
    "#padding to prepare sequences of same length\n",
    "x_tr_seq_vec  = pad_sequences(x_tr_seq_vec, maxlen=200)\n",
    "x_val_seq_vec = pad_sequences(x_val_seq_vec, maxlen=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dMZsJMBLPTSK",
    "outputId": "8ded3408-b9bd-42f2-99d8-a5eee5501337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8699\n"
     ]
    }
   ],
   "source": [
    "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iMFyot_PURX"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "PROJECT_DIR = \"/content/drive/My Drive/Colab Notebooks/\"\n",
    "EMBEDDING_FILE = 'SO_vectors_200.bin'\n",
    "EmbeddingFile = PROJECT_DIR+EMBEDDING_FILE\n",
    "word2vec = KeyedVectors.load_word2vec_format(EmbeddingFile, binary=True)\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLHuP8l_PWU3"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "EMBEDDING_DIM = 200\n",
    "embedding_matrix_word2vec = np.zeros((size_of_vocabulary, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix_word2vec[i] = word2vec.word_vec(word)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "rb6E-1p-PaLC",
    "outputId": "c5f16c2d-7d3f-4ede-b808-b96284ea2421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 200, 200)          1739800   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 200, 256)          336896    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 74)                9546      \n",
      "=================================================================\n",
      "Total params: 2,119,138\n",
      "Trainable params: 2,119,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,200,weights=[embedding_matrix_word2vec],input_length=200,trainable=True)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dense(74,activation='softmax'))  \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"acc\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "Gqa1lvlIQG9O",
    "outputId": "c63dd642-69c8-4a6d-b761-c98873c0c4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1700 samples\n",
      "Epoch 1/10\n",
      "6800/6800 [==============================] - 179s 26ms/step - loss: 2.0983 - acc: 0.5482 - val_loss: 1.6734 - val_acc: 0.5988\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59882, saving model to best_model.h5\n",
      "Epoch 2/10\n",
      "6800/6800 [==============================] - 175s 26ms/step - loss: 1.5635 - acc: 0.6162 - val_loss: 1.5037 - val_acc: 0.6247\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59882 to 0.62471, saving model to best_model.h5\n",
      "Epoch 3/10\n",
      "6800/6800 [==============================] - 175s 26ms/step - loss: 1.3636 - acc: 0.6499 - val_loss: 1.4390 - val_acc: 0.6329\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.62471 to 0.63294, saving model to best_model.h5\n",
      "Epoch 4/10\n",
      "6800/6800 [==============================] - 175s 26ms/step - loss: 1.2025 - acc: 0.6815 - val_loss: 1.3834 - val_acc: 0.6447\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.63294 to 0.64471, saving model to best_model.h5\n",
      "Epoch 5/10\n",
      "6800/6800 [==============================] - 175s 26ms/step - loss: 1.0617 - acc: 0.7197 - val_loss: 1.3735 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64471 to 0.65235, saving model to best_model.h5\n",
      "Epoch 6/10\n",
      "6800/6800 [==============================] - 176s 26ms/step - loss: 0.9343 - acc: 0.7534 - val_loss: 1.4272 - val_acc: 0.6453\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65235\n",
      "Epoch 7/10\n",
      "6800/6800 [==============================] - 175s 26ms/step - loss: 0.8423 - acc: 0.7807 - val_loss: 1.3897 - val_acc: 0.6553\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.65235 to 0.65529, saving model to best_model.h5\n",
      "Epoch 8/10\n",
      "6800/6800 [==============================] - 174s 26ms/step - loss: 0.7559 - acc: 0.8066 - val_loss: 1.4171 - val_acc: 0.6618\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.65529 to 0.66176, saving model to best_model.h5\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr_seq_vec,y_train_vec,batch_size=32,epochs=10,validation_data=(x_val_seq_vec,y_valid_vec),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ghwxa783VrJ3",
    "outputId": "ff693e9e-71c6-4a8d-c414-bda25d5805ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 10s 6ms/step\n",
      "0.6617646813392639\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "#evaluation \n",
    "_,val_acc = model.evaluate(x_val_seq_vec,y_valid_vec, batch_size=32)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F-j45_qchWlB"
   },
   "source": [
    "**FASTTEXT pre trained embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtVhqZICVsgp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "x_train_fast, x_valid_fast, y_train_fast, y_valid_fast = train_test_split(cleansed_data_df['combined_desc'], X, test_size=0.2, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "bxem78oQhwSp",
    "outputId": "89cb7656-f80f-4ef2-e71f-66c921f76eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 74, 2)\n",
      "8703\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_cate = to_categorical(y_train_fast)\n",
    "y_test_cate = to_categorical(y_valid_fast)\n",
    "print(y_train_cate.shape)\n",
    "\n",
    "x_train_fast = x_train_fast.astype(str)\n",
    "x_valid_fast = x_valid_fast.astype(str)\n",
    "\n",
    "#Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
    "\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(list(x_train_fast))\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq_fast  = tokenizer.texts_to_sequences(x_train_fast) \n",
    "x_val_seq_fast = tokenizer.texts_to_sequences(x_valid_fast)\n",
    "\n",
    "#padding to prepare sequences of same length\n",
    "x_tr_seq_fast  = pad_sequences(x_tr_seq_fast, maxlen=300)\n",
    "x_val_seq_fast = pad_sequences(x_val_seq_fast, maxlen=300)\n",
    "\n",
    "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAiSO87niTyK"
   },
   "outputs": [],
   "source": [
    "max_features = 200000 #17780 #using all unique words\n",
    "embedding_dim = 300\n",
    "num_classes = 74\n",
    "batch_size = 32\n",
    "\n",
    "embedding_path = \"/content/drive/My Drive/Colab Notebooks/wiki-news-300d-1M.vec\"\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix_fast = np.zeros((nb_words + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix_fast[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "9D5PgbSCiagU",
    "outputId": "fe942ee8-7182-4c84-b38a-9268c5d56798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 300, 300)          2610900   \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 300, 256)          439296    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 74)                9546      \n",
      "=================================================================\n",
      "Total params: 3,092,638\n",
      "Trainable params: 3,092,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,300,weights=[embedding_matrix_fast],input_length=300,trainable=True)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dense(74,activation='softmax'))  \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"acc\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "CMOMO1K9iduE",
    "outputId": "5fea2c43-9e73-49fa-bc19-f7e153fb5956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1700 samples\n",
      "Epoch 1/10\n",
      "6800/6800 [==============================] - 319s 47ms/step - loss: 2.2178 - acc: 0.5369 - val_loss: 1.8581 - val_acc: 0.5782\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.57824, saving model to best_model.h5\n",
      "Epoch 2/10\n",
      "6800/6800 [==============================] - 322s 47ms/step - loss: 1.6067 - acc: 0.6097 - val_loss: 1.6667 - val_acc: 0.5953\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.57824 to 0.59529, saving model to best_model.h5\n",
      "Epoch 3/10\n",
      "6800/6800 [==============================] - 322s 47ms/step - loss: 1.3123 - acc: 0.6609 - val_loss: 1.5353 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.59529 to 0.62000, saving model to best_model.h5\n",
      "Epoch 4/10\n",
      "6800/6800 [==============================] - 322s 47ms/step - loss: 1.0729 - acc: 0.7193 - val_loss: 1.5609 - val_acc: 0.6106\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.62000\n",
      "Epoch 5/10\n",
      "6800/6800 [==============================] - 324s 48ms/step - loss: 0.8841 - acc: 0.7700 - val_loss: 1.6742 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.62000 to 0.63706, saving model to best_model.h5\n",
      "Epoch 6/10\n",
      "6800/6800 [==============================] - 321s 47ms/step - loss: 0.7423 - acc: 0.8090 - val_loss: 1.6891 - val_acc: 0.6306\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.63706\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fca2e5f5860>"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tr_seq_fast,y_train_fast,batch_size=32,epochs=10,validation_data=(x_val_seq_fast,y_valid_fast),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xf3khDYWiej2",
    "outputId": "eb1c50c1-f5a4-4663-c7a1-6e6f1779b95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 16s 10ms/step\n",
      "0.6370587944984436\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "#evaluation \n",
    "_,val_acc = model.evaluate(x_val_seq_fast,y_valid_fast, batch_size=32)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHXt6PeuVtOy"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NewEmbedding_hotencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
