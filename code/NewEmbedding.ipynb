{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewEmbedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQNehRykEju9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.1.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEsLA0vF0TE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0ddec1ad-25bb-494b-c1bb-4667608aad37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hogv62O1F2tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_DIR = \"/content/drive/My Drive/Colab Notebooks/cleansed_data.csv\"\n",
        "DATA_FILE_NAME = 'My Drive/Colab Notebooks/input.xlsx'\n",
        "CLEANSED_FILE_DIR = '/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uv4c072H8ok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "131c2142-ba59-4ab2-d4fe-d45b3148a519"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crcb7k6-IGbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86d31e23-06ba-4094-9eb9-f170bf95a0d6"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Activation, Bidirectional, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQpKMRAcIZo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "  if(filename.endswith('.xlsx')):\n",
        "    data_df = pd.read_excel(filename, lines=True)\n",
        "  elif(filename.endswith('.csv')):\n",
        "    data_df = pd.read_csv(filename, keep_default_na = False)\n",
        "  return data_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CoyNMVRIdYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_target(target):\n",
        "  le = LabelEncoder()\n",
        "  return le.fit_transform(target), le\n",
        "\n",
        "def decode_prediction(pred, encoder):\n",
        "  return encoder.inverse_transform(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPbVspqMIiu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f799ed76-dbe0-4744-afac-23d26fce078b"
      },
      "source": [
        "cleansed_data_df = load_doc(PROJECT_DIR)\n",
        "print('shape of Data : ', cleansed_data_df.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of Data :  (8500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPtAl6Q5Izji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "a4d8994d-b8fe-43ef-9254-17ef9507b404"
      },
      "source": [
        "cleansed_data_df.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>short_description</th>\n",
              "      <th>description</th>\n",
              "      <th>combined_desc</th>\n",
              "      <th>assignment_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8500</td>\n",
              "      <td>8500</td>\n",
              "      <td>8500</td>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>6000</td>\n",
              "      <td>5484</td>\n",
              "      <td>5634</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>job job failed job scheduler</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>473</td>\n",
              "      <td>1123</td>\n",
              "      <td>1047</td>\n",
              "      <td>3976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   short_description description combined_desc assignment_group\n",
              "count                           8500        8500          8500             8500\n",
              "unique                          6000        5484          5634               74\n",
              "top     job job failed job scheduler                                      GRP_0\n",
              "freq                             473        1123          1047             3976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5rlps6XI6sC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "3d3e5605-28ae-46bf-9286-508f2fc8665f"
      },
      "source": [
        "cleansed_data_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>short_description</th>\n",
              "      <th>description</th>\n",
              "      <th>combined_desc</th>\n",
              "      <th>assignment_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verified user details employee manager checked...</td>\n",
              "      <td>login issue verified user details employee man...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meetings skype meetings etc not appearing...</td>\n",
              "      <td>outlook team meetings skype meetings etc not a...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>hi cannot log vpn</td>\n",
              "      <td>cant log vpn hi cannot log vpn</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page unable access hr to...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            short_description  ... assignment_group\n",
              "0                 login issue  ...            GRP_0\n",
              "1                     outlook  ...            GRP_0\n",
              "2                cant log vpn  ...            GRP_0\n",
              "3  unable access hr tool page  ...            GRP_0\n",
              "4                 skype error  ...            GRP_0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol7yVaf6JKYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "cleansed_data_df['assignment_group'] = labelencoder.fit_transform(cleansed_data_df['assignment_group'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GS9RJGiJUyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "37e86083-e293-4e0d-af29-bfb462e85394"
      },
      "source": [
        "cleansed_data_df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>short_description</th>\n",
              "      <th>description</th>\n",
              "      <th>combined_desc</th>\n",
              "      <th>assignment_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verified user details employee manager checked...</td>\n",
              "      <td>login issue verified user details employee man...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meetings skype meetings etc not appearing...</td>\n",
              "      <td>outlook team meetings skype meetings etc not a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>hi cannot log vpn</td>\n",
              "      <td>cant log vpn hi cannot log vpn</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page unable access hr to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8495</th>\n",
              "      <td>emails not coming zz mail</td>\n",
              "      <td>good afternoon not receiving emails sent zz ma...</td>\n",
              "      <td>emails not coming zz mail good afternoon not r...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8496</th>\n",
              "      <td>telephony software issue</td>\n",
              "      <td>telephony software issue</td>\n",
              "      <td>telephony software issue telephony software issue</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8497</th>\n",
              "      <td>windows password reset tifpdchb pedxruyf</td>\n",
              "      <td>windows password reset tifpdchb pedxruyf</td>\n",
              "      <td>windows password reset tifpdchb pedxruyf windo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8498</th>\n",
              "      <td>machine funcionando</td>\n",
              "      <td>unable access machine utilities finish drawers...</td>\n",
              "      <td>machine funcionando unable access machine util...</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8499</th>\n",
              "      <td>mehreren pc lassen sich verschiedene prgramdnt...</td>\n",
              "      <td>mehreren pc lassen sich verschiedene prgramdnt...</td>\n",
              "      <td>mehreren pc lassen sich verschiedene prgramdnt...</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8500 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      short_description  ... assignment_group\n",
              "0                                           login issue  ...                0\n",
              "1                                               outlook  ...                0\n",
              "2                                          cant log vpn  ...                0\n",
              "3                            unable access hr tool page  ...                0\n",
              "4                                           skype error  ...                0\n",
              "...                                                 ...  ...              ...\n",
              "8495                          emails not coming zz mail  ...               22\n",
              "8496                           telephony software issue  ...                0\n",
              "8497           windows password reset tifpdchb pedxruyf  ...                0\n",
              "8498                                machine funcionando  ...               59\n",
              "8499  mehreren pc lassen sich verschiedene prgramdnt...  ...               44\n",
              "\n",
              "[8500 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkVWGqu5JzgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(cleansed_data_df['combined_desc'], cleansed_data_df['assignment_group'], test_size=0.33, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp86EDeLJ-oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "544c8a6c-20ae-4136-8466-f0403a5fed36"
      },
      "source": [
        "y_train.head()\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2176    45\n",
              "933      5\n",
              "7578     0\n",
              "4202    11\n",
              "5442     0\n",
              "Name: assignment_group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp5K1mCmKFNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22a002db-cea6-4a49-9519-af98769ce491"
      },
      "source": [
        "print(x_train[22])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unable connect vpn unable connect vpn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb34e6QXKI0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af7eaae5-ddf3-4f13-bce8-c6e3e977c04c"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "y_train_cate = to_categorical(y_train)\n",
        "y_test_cate = to_categorical(y_valid)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train = x_train.astype(str)\n",
        "x_valid = x_valid.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq  = tokenizer.texts_to_sequences(x_train) \n",
        "x_val_seq = tokenizer.texts_to_sequences(x_valid)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq  = pad_sequences(x_tr_seq, maxlen=200)\n",
        "x_val_seq = pad_sequences(x_val_seq, maxlen=200)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5695, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6RYIWcDKOJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "46be00ef-46fe-427f-f24f-57b241d9b4e4"
      },
      "source": [
        "print(x_train[22])\n",
        "print(x_tr_seq[22])\n",
        "#print(x_train[24])\n",
        "#print(x_tr_seq[22])\n",
        "#print(x_tr_seq[24])\n",
        "#print(x_tr_seq[25])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unable connect vpn unable connect vpn\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 238  11  45\n",
            " 238  11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJcRpF_0LHDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "57d4fe87-6623-4d5c-a21a-7cc66b3839e2"
      },
      "source": [
        "y_train = np.asarray(y_train)\n",
        "print(y_train.shape)\n",
        "type(y_train)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5695,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNL3-jr6LKTJ",
        "colab_type": "text"
      },
      "source": [
        "**Pretrained Glove embeddings with 100d**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS7Hele3LPxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6eaba22f-717c-4672-ecea-a869528b18df"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('../content/drive/My Drive/Colab Notebooks/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUc6K4O7LeZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d012f6c-d015-4a4b-f82e-1f96cda5cd39"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH56rLNhLgws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((size_of_vocabulary, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnVRGWM6LldI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V9tO3SNLoXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "6f31b85f-ffd8-4292-bc48-5865944fa89a"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(size_of_vocabulary,100,weights=[embedding_matrix],input_length=200,trainable=True)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax'))  \n",
        "\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 200, 100)          781400    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 200, 256)          234496    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 74)                9546      \n",
            "=================================================================\n",
            "Total params: 1,058,338\n",
            "Trainable params: 1,058,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH0-vujqLqRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "b0945cb5-dc5e-4f58-add5-5e2da00e450b"
      },
      "source": [
        "history = model.fit(x_tr_seq,y_train,batch_size=32,epochs=10,validation_data=(x_val_seq,y_valid),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5695 samples, validate on 2805 samples\n",
            "Epoch 1/10\n",
            "5695/5695 [==============================] - 110s 19ms/step - loss: 2.3004 - acc: 0.5198 - val_loss: 1.9488 - val_acc: 0.5558\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.55579, saving model to best_model.h5\n",
            "Epoch 2/10\n",
            "5695/5695 [==============================] - 109s 19ms/step - loss: 1.7865 - acc: 0.5777 - val_loss: 1.7954 - val_acc: 0.5843\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.55579 to 0.58431, saving model to best_model.h5\n",
            "Epoch 3/10\n",
            "5695/5695 [==============================] - 108s 19ms/step - loss: 1.5725 - acc: 0.6174 - val_loss: 1.6393 - val_acc: 0.6018\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.58431 to 0.60178, saving model to best_model.h5\n",
            "Epoch 4/10\n",
            "5695/5695 [==============================] - 108s 19ms/step - loss: 1.3931 - acc: 0.6386 - val_loss: 1.5727 - val_acc: 0.6164\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.60178 to 0.61640, saving model to best_model.h5\n",
            "Epoch 5/10\n",
            "5695/5695 [==============================] - 108s 19ms/step - loss: 1.2533 - acc: 0.6788 - val_loss: 1.5351 - val_acc: 0.6217\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.61640 to 0.62175, saving model to best_model.h5\n",
            "Epoch 6/10\n",
            "5695/5695 [==============================] - 108s 19ms/step - loss: 1.1194 - acc: 0.7099 - val_loss: 1.5161 - val_acc: 0.6228\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.62175 to 0.62282, saving model to best_model.h5\n",
            "Epoch 7/10\n",
            "5695/5695 [==============================] - 108s 19ms/step - loss: 1.0004 - acc: 0.7373 - val_loss: 1.5343 - val_acc: 0.6257\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.62282 to 0.62567, saving model to best_model.h5\n",
            "Epoch 8/10\n",
            "5695/5695 [==============================] - 109s 19ms/step - loss: 0.9078 - acc: 0.7554 - val_loss: 1.5843 - val_acc: 0.6253\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.62567\n",
            "Epoch 9/10\n",
            "5695/5695 [==============================] - 109s 19ms/step - loss: 0.8155 - acc: 0.7853 - val_loss: 1.6532 - val_acc: 0.6285\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.62567 to 0.62852, saving model to best_model.h5\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56KLpw8rLuRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75fff772-ce06-4668-d639-e57e63b8c9d2"
      },
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,val_acc = model.evaluate(x_val_seq,y_valid, batch_size=32)\n",
        "print(val_acc)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2805/2805 [==============================] - 9s 3ms/step\n",
            "0.6285204887390137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSR5vYPPLyhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "1d3f22e0-e75b-4cbf-cc01-c5c87d53752f"
      },
      "source": [
        "pip install --upgrade gensim"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.8.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (1.13.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaT8Do6_L0mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train_vec, x_valid_vec, y_train_vec, y_valid_vec = train_test_split(cleansed_data_df['combined_desc'], cleansed_data_df['assignment_group'], test_size=0.33, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al02LNwqPQkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33fcd67b-50e5-44f7-880e-d02a793492ec"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train_vec)\n",
        "y_test_cate = to_categorical(y_train_vec)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train_vec = x_train_vec.astype(str)\n",
        "x_valid_vec = x_valid_vec.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(x_train_vec)\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq_vec  = tokenizer.texts_to_sequences(x_train_vec) \n",
        "x_val_seq_vec = tokenizer.texts_to_sequences(x_valid_vec)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq_vec  = pad_sequences(x_tr_seq_vec, maxlen=200)\n",
        "x_val_seq_vec = pad_sequences(x_val_seq_vec, maxlen=200)\n",
        "\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5695, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMZsJMBLPTSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74b0fe58-586d-4903-bf0a-d4feb33479f5"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iMFyot_PURX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "PROJECT_DIR = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "EMBEDDING_FILE = 'SO_vectors_200.bin'\n",
        "EmbeddingFile = PROJECT_DIR+EMBEDDING_FILE\n",
        "word2vec = KeyedVectors.load_word2vec_format(EmbeddingFile, binary=True)\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "MAX_NB_WORDS = 200000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLHuP8l_PWU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "EMBEDDING_DIM = 200\n",
        "embedding_matrix_word2vec = np.zeros((size_of_vocabulary, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embedding_matrix_word2vec[i] = word2vec.word_vec(word)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb6E-1p-PaLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "d27f31e3-7381-4728-ef9a-dcc0bfb34486"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(size_of_vocabulary,200,weights=[embedding_matrix_word2vec],input_length=200,trainable=True)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax'))  \n",
        "\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 200, 200)          1613000   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 200, 256)          336896    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 74)                9546      \n",
            "=================================================================\n",
            "Total params: 1,992,338\n",
            "Trainable params: 1,992,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqa1lvlIQG9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "1a493122-aea5-46c5-e8de-13d0f31332fa"
      },
      "source": [
        "history = model.fit(x_tr_seq_vec,y_train_vec,batch_size=32,epochs=10,validation_data=(x_val_seq_vec,y_valid_vec),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5695 samples, validate on 2805 samples\n",
            "Epoch 1/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 2.1597 - acc: 0.5387 - val_loss: 1.7324 - val_acc: 0.5925\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.59251, saving model to best_model.h5\n",
            "Epoch 2/10\n",
            "5695/5695 [==============================] - 155s 27ms/step - loss: 1.6080 - acc: 0.6042 - val_loss: 1.5298 - val_acc: 0.6271\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.59251 to 0.62709, saving model to best_model.h5\n",
            "Epoch 3/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 1.3883 - acc: 0.6427 - val_loss: 1.4607 - val_acc: 0.6399\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.62709 to 0.63993, saving model to best_model.h5\n",
            "Epoch 4/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 1.2304 - acc: 0.6715 - val_loss: 1.4076 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.63993 to 0.64742, saving model to best_model.h5\n",
            "Epoch 5/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 1.0961 - acc: 0.7057 - val_loss: 1.4033 - val_acc: 0.6339\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.64742\n",
            "Epoch 6/10\n",
            "5695/5695 [==============================] - 155s 27ms/step - loss: 0.9618 - acc: 0.7487 - val_loss: 1.3993 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.64742\n",
            "Epoch 7/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 0.8536 - acc: 0.7795 - val_loss: 1.3983 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.64742\n",
            "Epoch 8/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 0.7611 - acc: 0.8046 - val_loss: 1.4450 - val_acc: 0.6520\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.64742 to 0.65205, saving model to best_model.h5\n",
            "Epoch 9/10\n",
            "5695/5695 [==============================] - 154s 27ms/step - loss: 0.6897 - acc: 0.8195 - val_loss: 1.4517 - val_acc: 0.6513\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.65205\n",
            "Epoch 10/10\n",
            "5695/5695 [==============================] - 155s 27ms/step - loss: 0.6285 - acc: 0.8372 - val_loss: 1.4901 - val_acc: 0.6553\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.65205 to 0.65526, saving model to best_model.h5\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghwxa783VrJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c2dcf132-b6a7-482c-edfc-ee49bb41ff51"
      },
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,val_acc = model.evaluate(x_val_seq_vec,y_valid_vec, batch_size=32)\n",
        "print(val_acc)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2805/2805 [==============================] - 16s 6ms/step\n",
            "0.6552584767341614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-j45_qchWlB",
        "colab_type": "text"
      },
      "source": [
        "**FASTTEXT pre trained embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtVhqZICVsgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train_fast, x_valid_fast, y_train_fast, y_valid_fast = train_test_split(cleansed_data_df['combined_desc'], cleansed_data_df['assignment_group'], test_size=0.33, shuffle= True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxem78oQhwSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7b8cd49f-0435-4fb2-cd3d-5472aec78400"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train_fast)\n",
        "y_test_cate = to_categorical(y_valid_fast)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train_fast = x_train_fast.astype(str)\n",
        "x_valid_fast = x_valid_fast.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(list(x_train_fast))\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq_fast  = tokenizer.texts_to_sequences(x_train_fast) \n",
        "x_val_seq_fast = tokenizer.texts_to_sequences(x_valid_fast)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq_fast  = pad_sequences(x_tr_seq_fast, maxlen=300)\n",
        "x_val_seq_fast = pad_sequences(x_val_seq_fast, maxlen=300)\n",
        "\n",
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5695, 74)\n",
            "7947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAiSO87niTyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 200000 #17780 #using all unique words\n",
        "embedding_dim = 300\n",
        "num_classes = 74\n",
        "batch_size = 32\n",
        "\n",
        "embedding_path = \"/content/drive/My Drive/Colab Notebooks/wiki-news-300d-1M.vec\"\n",
        "\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = len(word_index)\n",
        "embedding_matrix_fast = np.zeros((nb_words + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix_fast[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D5PgbSCiagU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "10f474f4-4bbc-4fa4-c23a-742d8d3ff8e8"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(size_of_vocabulary,300,weights=[embedding_matrix_fast],input_length=300,trainable=True)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax'))  \n",
        "\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 300, 300)          2384100   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 300, 256)          439296    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_10 (Glo (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 74)                9546      \n",
            "=================================================================\n",
            "Total params: 2,865,838\n",
            "Trainable params: 2,865,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOMO1K9iduE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "29e1abec-524b-46f9-a7cf-b48f69b78d3f"
      },
      "source": [
        "model.fit(x_tr_seq_fast,y_train_fast,batch_size=32,epochs=10,validation_data=(x_val_seq_fast,y_valid_fast),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5695 samples, validate on 2805 samples\n",
            "Epoch 1/10\n",
            "5695/5695 [==============================] - 284s 50ms/step - loss: 2.2602 - acc: 0.5250 - val_loss: 1.8556 - val_acc: 0.5768\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57683, saving model to best_model.h5\n",
            "Epoch 2/10\n",
            "5695/5695 [==============================] - 285s 50ms/step - loss: 1.6641 - acc: 0.6000 - val_loss: 1.6567 - val_acc: 0.6029\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57683 to 0.60285, saving model to best_model.h5\n",
            "Epoch 3/10\n",
            "5695/5695 [==============================] - 284s 50ms/step - loss: 1.3629 - acc: 0.6637 - val_loss: 1.6104 - val_acc: 0.6185\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.60285 to 0.61854, saving model to best_model.h5\n",
            "Epoch 4/10\n",
            "5695/5695 [==============================] - 283s 50ms/step - loss: 1.1398 - acc: 0.7096 - val_loss: 1.6238 - val_acc: 0.6178\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61854\n",
            "Epoch 5/10\n",
            "5695/5695 [==============================] - 283s 50ms/step - loss: 0.9520 - acc: 0.7615 - val_loss: 1.6653 - val_acc: 0.6264\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.61854 to 0.62638, saving model to best_model.h5\n",
            "Epoch 6/10\n",
            "5695/5695 [==============================] - 284s 50ms/step - loss: 0.8006 - acc: 0.7942 - val_loss: 1.7155 - val_acc: 0.6143\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.62638\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fb735985cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf3khDYWiej2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e8f8051f-cf6d-456b-e84a-8e708aa7faee"
      },
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,val_acc = model.evaluate(x_val_seq_fast,y_valid_fast, batch_size=32)\n",
        "print(val_acc)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2805/2805 [==============================] - 26s 9ms/step\n",
            "0.6263814568519592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHXt6PeuVtOy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}