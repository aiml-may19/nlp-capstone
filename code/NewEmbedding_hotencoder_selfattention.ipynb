{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewEmbedding_hotencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQNehRykEju9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.1.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnAWKorwCO9z",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEsLA0vF0TE",
        "colab_type": "code",
        "outputId": "7b78683a-7430-4b48-cc39-5877fb480f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hogv62O1F2tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_DIR = \"/content/drive/My Drive/Colab Notebooks/cleansed_data.csv\"\n",
        "DATA_FILE_NAME = 'My Drive/Colab Notebooks/input_data.xlsx'\n",
        "CLEANSED_FILE_DIR = '/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uv4c072H8ok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "834bd259-a1a0-4cd8-c36a-33549a1ac67c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crcb7k6-IGbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dc20978-6e2b-4604-a444-8d5bb789e1ca"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding , Activation, Bidirectional, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQpKMRAcIZo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "  if(filename.endswith('.xlsx')):\n",
        "    data_df = pd.read_excel(filename, lines=True)\n",
        "  elif(filename.endswith('.csv')):\n",
        "    data_df = pd.read_csv(filename, keep_default_na = False,delimiter=',')\n",
        "  return data_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CoyNMVRIdYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_target(target):\n",
        "  le = LabelEncoder()\n",
        "  return le.fit_transform(target), le\n",
        "\n",
        "def decode_prediction(pred, encoder):\n",
        "  return encoder.inverse_transform(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPbVspqMIiu4",
        "colab_type": "code",
        "outputId": "1dda0e8e-56c0-4afd-c7c3-ff48294a8d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cleansed_data_df = load_doc(\"/content/drive/My Drive/Colab Notebooks/input_data.xlsx\")\n",
        "print('shape of Data : ', cleansed_data_df.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of Data :  (8500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPtAl6Q5Izji",
        "colab_type": "code",
        "outputId": "a716d6ee-7a17-4e90-e013-24c8d0229d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "cleansed_data_df.describe()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8492</td>\n",
              "      <td>8499</td>\n",
              "      <td>8500</td>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>7481</td>\n",
              "      <td>7817</td>\n",
              "      <td>2950</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>password reset</td>\n",
              "      <td>the</td>\n",
              "      <td>bpctwhsn kzqsbmtp</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>38</td>\n",
              "      <td>56</td>\n",
              "      <td>810</td>\n",
              "      <td>3976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Short description Description             Caller Assignment group\n",
              "count               8492        8499               8500             8500\n",
              "unique              7481        7817               2950               74\n",
              "top       password reset         the  bpctwhsn kzqsbmtp            GRP_0\n",
              "freq                  38          56                810             3976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5rlps6XI6sC",
        "colab_type": "code",
        "outputId": "1860cde1-6aa4-4d77-ea4e-f3e903460663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "cleansed_data_df.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>-verified user details.(employee# &amp; manager na...</td>\n",
              "      <td>spxjnwir pjlcoqds</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n",
              "      <td>hmjdrvpb komuaywn</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log in to vpn</td>\n",
              "      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n",
              "      <td>eylqgodm ybqkwiam</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>xbkucsvz gcpydteq</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>owlgqjme qhcozdfx</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Short description  ... Assignment group\n",
              "0                    login issue  ...            GRP_0\n",
              "1                        outlook  ...            GRP_0\n",
              "2             cant log in to vpn  ...            GRP_0\n",
              "3  unable to access hr_tool page  ...            GRP_0\n",
              "4                   skype error   ...            GRP_0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCjrBSjIpK-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data_df[\"Short description\"].fillna(\"The\", inplace=True)\n",
        "cleansed_data_df[\"Description\"].fillna(\"The\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Mb7roVpLC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data = cleansed_data_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKVTtF61pLGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24ee3551-8c1f-4375-dc6e-2b71ee886a5d"
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V29GU6VCpvJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punct(text):\n",
        "    text = re.sub('[0-9]+|\\n|\\r|[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', ' ', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIjqlPvRpvPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "cleansed_data['Description_new'] = cleansed_data['Description'].apply(lambda x: remove_punct(x))\n",
        "cleansed_data['Short description'] = cleansed_data['Short description'].apply(lambda x: remove_punct(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YERSiOlSpvTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjphrBY0rdwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLGSqEe5rQ_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b5874ea9-9f1f-44d1-c284-88ace0140382"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4hKXOjEpvNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a537b1f2-3ce4-4bf3-f7fb-beaea2f90002"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "print(stop_words)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'down', 'all', 'out', 'ma', 'been', 'very', 'where', 'not', \"you're\", 'ourselves', \"weren't\", 'against', \"you've\", \"shouldn't\", 'same', 're', \"wouldn't\", \"you'll\", 'my', 'which', \"shan't\", 'she', 'her', 'won', 'off', 'these', 'mightn', 'haven', 'again', \"doesn't\", 'they', \"that'll\", 'but', \"won't\", 'those', 'shouldn', 'a', \"mightn't\", 'who', 'now', 'don', 'll', 'in', 'him', 'that', 'into', 'an', 'needn', 'we', 'the', 'weren', 'during', 'm', 'through', 'didn', \"don't\", 'it', 'at', 'be', 'over', 'each', 'd', 'you', 'have', 'below', 'any', 'me', 'only', 'mustn', 'our', 'shan', 's', 'too', 'doing', 'what', 'how', 'most', 't', 'isn', \"didn't\", \"couldn't\", \"hadn't\", 'hadn', 'yours', 'did', 'yourself', \"hasn't\", 'will', 'their', 'were', 'no', 'your', 'just', \"it's\", 'nor', 'ours', 'themselves', 'by', 'couldn', 'few', 'of', 'is', 'from', 'i', 'while', 'there', 'can', 'such', 'am', 'here', 'both', 'up', 'should', \"she's\", 'itself', 'had', 'once', 'own', \"needn't\", 'theirs', 'above', 'between', \"aren't\", 'hasn', 'why', \"you'd\", 'he', 'are', 'this', 'if', 'further', 'other', 'more', \"mustn't\", 'doesn', 'on', 'himself', 'for', 'ain', 'having', 'was', 'because', 'wouldn', 'myself', 'and', 'to', 'then', 've', 'hers', 'about', 'yourselves', 'so', \"isn't\", \"wasn't\", 'do', 'until', 'before', 'aren', 'herself', 'some', 'o', 'when', 'wasn', 'its', 'or', 'after', \"haven't\", 'whom', 'as', 'his', 'under', \"should've\", 'does', 'than', 'with', 'has', 'y', 'being', 'them'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oPWIMfDpvMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data['Description_new1'] = cleansed_data['Description_new'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "cleansed_data['Short description'] = cleansed_data['Short description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7JwPIEppvH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "d8593fea-61ce-4c77-81e0-dc9e0b03a2c1"
      },
      "source": [
        "cleansed_data[['Description','Description_new','Description_new1']].head(10)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Description_new</th>\n",
              "      <th>Description_new1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-verified user details.(employee# &amp; manager na...</td>\n",
              "      <td>verified user details  employee    manager na...</td>\n",
              "      <td>verified user details employee manager name ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n",
              "      <td>received from  hmjdrvpb komuaywn gmail com...</td>\n",
              "      <td>received hmjdrvpb komuaywn gmail com hello tea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n",
              "      <td>received from  eylqgodm ybqkwiam gmail com...</td>\n",
              "      <td>received eylqgodm ybqkwiam gmail com hi cannot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>unable to access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>unable to log in to engineering tool and skype</td>\n",
              "      <td>unable to log in to engineering tool and skype</td>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>event: critical:HostName_221.company.com the v...</td>\n",
              "      <td>event  critical HostName   company com the val...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ticket_no1550391- employment status - new non-...</td>\n",
              "      <td>ticket no   employment status   new non employ...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>unable to disable add ins on outlook</td>\n",
              "      <td>unable to disable add ins on outlook</td>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ticket update on inplant_874773</td>\n",
              "      <td>ticket update on inplant</td>\n",
              "      <td>ticket update inplant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Description  ...                                   Description_new1\n",
              "0  -verified user details.(employee# & manager na...  ...  verified user details employee manager name ch...\n",
              "1  \\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...  ...  received hmjdrvpb komuaywn gmail com hello tea...\n",
              "2  \\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...  ...  received eylqgodm ybqkwiam gmail com hi cannot...\n",
              "3                      unable to access hr_tool page  ...                         unable access hr tool page\n",
              "4                                       skype error   ...                                        skype error\n",
              "5     unable to log in to engineering tool and skype  ...                  unable log engineering tool skype\n",
              "6  event: critical:HostName_221.company.com the v...  ...  event critical HostName company com value moun...\n",
              "7  ticket_no1550391- employment status - new non-...  ...  ticket employment status new non employee ente...\n",
              "8               unable to disable add ins on outlook  ...                     unable disable add ins outlook\n",
              "9                    ticket update on inplant_874773  ...                              ticket update inplant\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xFCi0tosOXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data['Description'] = cleansed_data['Description_new1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Z_Hf3gsOJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "text1 = \"THIS COMMUNICATION IS INTENDED FOR THE SOLE USE OF THE PERSON TO WHOM IT IS ADDRESSED AND MAY CONTAIN INFORMATION THAT IS PRIVILEGED, CONFIDENTIAL AND EXEMPT FROM DISCLOSURE UNDER APPLICABLE LAW. ANY DISSEMINATION, DISTRIBUTION OR DUPLICATION OF THIS COMMUNICATION BY SOMEONE OTHER THAN THE INTENDED RECIPIENT IS STRICTLY PROHIBITED. IF YOUR RECEIPT OF THIS COMMUNICATION IS IN ERROR, PLEASE NOTIFY THE SENDER AND DELETE THIS COMMUNICATION\"\n",
        "cleansed_data['Description'] = cleansed_data['Description'].apply(lambda x: re.sub(text1,'',x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKtPVyc3sOTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2 = \"Select the following link to view the Disclaimer in an alternate language.\"\n",
        "cleansed_data['Description'] = cleansed_data['Description'].apply(lambda x: re.sub(text2,'',x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke9ad9-ZsO6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data[\"SD - DD\"] = cleansed_data['Short description'].str.cat(cleansed_data[\"Description\"], sep= ' - ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO3BtMYEsO_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "7d32cd63-f4ed-4ec5-ba60-0a9517863a10"
      },
      "source": [
        "print(cleansed_data.columns)\n",
        "cleansed_data.head(10)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Short description', 'Description', 'Caller', 'Assignment group',\n",
            "       'Description_new', 'Description_new1', 'SD - DD'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>Description_new</th>\n",
              "      <th>Description_new1</th>\n",
              "      <th>SD - DD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verified user details employee manager name ch...</td>\n",
              "      <td>spxjnwir pjlcoqds</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>verified user details  employee    manager na...</td>\n",
              "      <td>verified user details employee manager name ch...</td>\n",
              "      <td>login issue - verified user details employee m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>received hmjdrvpb komuaywn gmail com hello tea...</td>\n",
              "      <td>hmjdrvpb komuaywn</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>received from  hmjdrvpb komuaywn gmail com...</td>\n",
              "      <td>received hmjdrvpb komuaywn gmail com hello tea...</td>\n",
              "      <td>outlook - received hmjdrvpb komuaywn gmail com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>received eylqgodm ybqkwiam gmail com hi cannot...</td>\n",
              "      <td>eylqgodm ybqkwiam</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>received from  eylqgodm ybqkwiam gmail com...</td>\n",
              "      <td>received eylqgodm ybqkwiam gmail com hi cannot...</td>\n",
              "      <td>cant log vpn - received eylqgodm ybqkwiam gmai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>xbkucsvz gcpydteq</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page - unable access hr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>owlgqjme qhcozdfx</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error - skype error</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "      <td>eflahbxn ltdgrvkz</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to log in to engineering tool and skype</td>\n",
              "      <td>unable log engineering tool skype</td>\n",
              "      <td>unable log engineering tool skype - unable log...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "      <td>jyoqwxhz clhxsoqy</td>\n",
              "      <td>GRP_1</td>\n",
              "      <td>event  critical HostName   company com the val...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "      <td>event critical HostName company com value moun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "      <td>eqzibjhw ymebpoih</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>ticket no   employment status   new non employ...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "      <td>ticket employment status new non employee ente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "      <td>mdbegvct dbvichlg</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to disable add ins on outlook</td>\n",
              "      <td>unable disable add ins outlook</td>\n",
              "      <td>unable disable add ins outlook - unable disabl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ticket update inplant</td>\n",
              "      <td>ticket update inplant</td>\n",
              "      <td>fumkcsji sarmtlhy</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>ticket update on inplant</td>\n",
              "      <td>ticket update inplant</td>\n",
              "      <td>ticket update inplant - ticket update inplant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Short description  ...                                            SD - DD\n",
              "0                                        login issue  ...  login issue - verified user details employee m...\n",
              "1                                            outlook  ...  outlook - received hmjdrvpb komuaywn gmail com...\n",
              "2                                       cant log vpn  ...  cant log vpn - received eylqgodm ybqkwiam gmai...\n",
              "3                         unable access hr tool page  ...  unable access hr tool page - unable access hr ...\n",
              "4                                        skype error  ...                          skype error - skype error\n",
              "5                  unable log engineering tool skype  ...  unable log engineering tool skype - unable log...\n",
              "6  event critical HostName company com value moun...  ...  event critical HostName company com value moun...\n",
              "7  ticket employment status new non employee ente...  ...  ticket employment status new non employee ente...\n",
              "8                     unable disable add ins outlook  ...  unable disable add ins outlook - unable disabl...\n",
              "9                              ticket update inplant  ...      ticket update inplant - ticket update inplant\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol7yVaf6JKYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "cleansed_data['Assignment group'] = labelencoder.fit_transform(cleansed_data['Assignment group'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Fpsr7jiBP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_count = cleansed_data['Assignment group'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srC4ywBLiV2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4b37f5bf-d2c4-4be7-bf3a-87ae8d757cba"
      },
      "source": [
        "(target_count<=10).value_counts()"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    49\n",
              "True     25\n",
              "Name: Assignment group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trqdBJKYSi_S",
        "colab_type": "code",
        "outputId": "fe21c603-b05c-4216-c602-200a750ed95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "oneHotencoder = OneHotEncoder()\n",
        "\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = oneHotencoder.fit_transform(cleansed_data['Assignment group'].values.reshape(-1,1)).toarray()\n",
        "print(X)\n",
        "#print(cleansed_data.shape[1])\n",
        "#To add this back into the original dataframe \n",
        "#dfOneHot = pd.DataFrame(X, columns = [\"assignment_group_\"+str(int(i)) for i in range(cleansed_data.shape[1])]) \n",
        "#df = pd.concat([cleansed_data, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "#df= df.drop(['assignment_group'], axis=1) \n",
        "#printing to verify \n",
        "#print(df.head())\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUzmj81Cb4KZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train_keras, x_test_keras, y_train_keras, y_test_keras = train_test_split(cleansed_data['SD - DD'], X, test_size=0.15, shuffle= True)\n",
        "x_train_keras, x_valid_keras, y_train_keras, y_valid_keras = train_test_split(x_train_keras, y_train_keras, test_size=0.15, shuffle= True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fIyS_khNQMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d4437c78-7abb-4e67-c992-521ede3273e9"
      },
      "source": [
        "print(x_train_keras.shape)\n",
        "print(x_valid_keras.shape)\n",
        "print(x_test_keras.shape)\n",
        "print(y_train_keras.shape)\n",
        "print(y_valid_keras.shape)\n",
        "print(y_test_keras.shape)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6141,)\n",
            "(1084,)\n",
            "(1275,)\n",
            "(6141, 74)\n",
            "(1084, 74)\n",
            "(1275, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGoCfOo8PYXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG_k9EQYNQcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 10000\n",
        "# finally, vectorize the text samples into a 2D integer tensor\n",
        "tokenizer = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenizer.fit_on_texts(x_train_keras)\n",
        "sequences_train = tokenizer.texts_to_sequences(x_train_keras)\n",
        "sequences_valid = tokenizer.texts_to_sequences(x_valid_keras)\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx_-1DR0NQjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "75d57634-90d8-4a6b-b14f-71484ee2450d"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 150\n",
        "\n",
        "# pad sequences with 0s\n",
        "X_train = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_valid = pad_sequences(sequences_valid, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_train.shape)\n",
        "print('Shape of data test tensor:', X_test.shape)\n",
        "print('Shape of data validation tensor:', X_valid.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (6141, 150)\n",
            "Shape of data test tensor: (1275, 150)\n",
            "Shape of data validation tensor: (1084, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFdm8F-n0QLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1284e4e1-c4a0-4d8a-e577-1638ce643302"
      },
      "source": [
        "type(x_train_keras)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkOzkxzs1MP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dae73e01-548f-4b3e-8db1-d1c35dc22cfc"
      },
      "source": [
        "x_train_keras.head()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "616     uacyltoe hxgaycze ticket - uacyltoe hxgaycze t...\n",
              "6632    access requited vl n post goods issues - recei...\n",
              "6220    problem erp logon - received zaeduhlt jdgsamtv...\n",
              "5933    msc communicating erp - name tmyeqika hfudpeot...\n",
              "3252    purchasing menue shopping cart working correct...\n",
              "Name: SD - DD, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6yYLOHx1ckg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3378e23a-abc3-419b-c6d1-99be1d845963"
      },
      "source": [
        "X_train[0:6]"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  158,  193,   21,  158,  193,   21],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   18,\n",
              "        7582, 1635,  323,  590,  752,  141,    5, 3766, 3767,    8,    2,\n",
              "         324,  292,    7,   52,   18, 7583, 7584,  637,  138,  590,  752,\n",
              "         141,  803, 1636, 3768, 7585, 7586,  426],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          91,    9,  383,    5, 7587, 7588,    8,    2,   53,   48,  116,\n",
              "        1082,   40,   20,   81,  316,  344,   88],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0, 2108, 3769,    9,   35, 7589,\n",
              "        7590,  144,  178,   96,  121,  170,   29, 7591, 7592, 1890,    2,\n",
              "          78,   76,  192,  112, 2108, 3769,    9],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,  408, 7593,\n",
              "        2663, 7594,   31,  366,   61,  118,  350],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,   28, 1326,   28, 1326]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NHiio8MRMSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "881a43e4-39e8-4e37-9d94-d8be5c232af2"
      },
      "source": [
        "print(x_train_keras.iloc[30])\n",
        "print(X_train[30])\n",
        "print(x_train_keras.iloc[26])\n",
        "print(X_train[26])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "system frozen startup - system frozen startup\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0   34 2112 1572   34 2112 1572]\n",
            "erp netweaver enterence please help aerp - received chbvyjqr dqbwijvy gmail com colleagues enter programdntys need immediately please help aerp please see cid image png b b cid image png b b best\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    9  473 7615    7   32  494    5 7616\n",
            " 7617    8    2 1247  281 1476   36  623    7   32  494    7   61   53\n",
            "   48  116   40   40   53   48  116   40   40   88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLX4mcKvBq_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79c4f09e-a56e-4e56-b9bf-7003e94a80a3"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('../content/drive/My Drive/Colab Notebooks/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 7341 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6geJm8jGiAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05a62f67-b6c1-447e-b408-b19e66fd60eb"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWj1EAKlC0nC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((size_of_vocabulary, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xdd5YBiNQnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, Flatten, BatchNormalization, Dropout\n",
        "from keras.layers import GlobalAveragePooling1D, Embedding, LSTM, Bidirectional\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyLjPjAFU7v9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "b89ff8f5-f28c-4b40-bd9b-eb48c0baa78d"
      },
      "source": [
        "pip install keras_self_attention"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_self_attention\n",
            "  Downloading https://files.pythonhosted.org/packages/44/3e/eb1a7c7545eede073ceda2f5d78442b6cad33b5b750d7f0742866907c34b/keras-self-attention-0.42.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (1.18.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.0.8)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.42.0-cp36-none-any.whl size=17296 sha256=e75dc9c0d894a9081135ee604e24283621d1d64b95977ac6adf0868c82b28f4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/05/a0/99c0cf60d383f0494e10eca2b238ea98faca9a1fe03cac2894\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuFfZizOVGZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_self_attention import SeqSelfAttention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsd93zB6NQrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "#EMBEDDING_DIM = 100\n",
        "#N_CLASSES = 74\n",
        "\n",
        "#sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "#embedding_layer = Embedding(max_words, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)\n",
        "#embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "#x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\n",
        "#predictions = Dense(N_CLASSES, activation='softmax')(x)\n",
        "\n",
        "#model = Model(sequence_input, predictions)\n",
        "#opt = Adam(lr = 0.001)\n",
        "#model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['acc'])\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "#es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "#rlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=0, mode=\"auto\", min_delta=0.0001, cooldown=0)\n",
        "#mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMxARhdjW_Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "#embedding layer\n",
        "#model.add(Input(shape=(150,)))\n",
        "model.add(Embedding(size_of_vocabulary,100,weights=[embedding_matrix],input_length=150,trainable=True)) \n",
        "\n",
        "#Bilstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2,recurrent_dropout=0.2)))\n",
        "model.add(SeqSelfAttention(units = 32, attention_activation='relu'))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "#model.add(Dense(256,activation='relu'))  \n",
        "#model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(74,activation='softmax')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PVZZEpsXf9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "rlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=0, mode=\"auto\", min_delta=0.0001, cooldown=0)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IuBLMYe5Vhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "cf5bfbdc-1349-41f4-a06b-4bf0cdac327e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_29 (Embedding)     (None, 150, 100)          1295200   \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 150, 256)          234496    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_2 (SeqSel (None, 150, 256)          16449     \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 38400)             0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 74)                2841674   \n",
            "=================================================================\n",
            "Total params: 4,387,819\n",
            "Trainable params: 4,387,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WISFvFecdEIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7f8a0cd-4fce-441d-f1be-e1de540c8282"
      },
      "source": [
        "historical = model.fit(X_train,y_train_keras,batch_size=32,epochs=50,validation_data=(X_valid,y_valid_keras),verbose=1,callbacks=[es,rlr,mc])"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6141 samples, validate on 1084 samples\n",
            "Epoch 1/50\n",
            "6141/6141 [==============================] - 122s 20ms/step - loss: 2.1922 - acc: 0.5261 - val_loss: 1.8028 - val_acc: 0.5839\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.58395, saving model to best_model.h5\n",
            "Epoch 2/50\n",
            "6141/6141 [==============================] - 121s 20ms/step - loss: 1.6015 - acc: 0.6061 - val_loss: 1.6445 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.58395 to 0.60609, saving model to best_model.h5\n",
            "Epoch 3/50\n",
            "6141/6141 [==============================] - 121s 20ms/step - loss: 1.1743 - acc: 0.6794 - val_loss: 1.4719 - val_acc: 0.6513\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.60609 to 0.65129, saving model to best_model.h5\n",
            "Epoch 4/50\n",
            "6141/6141 [==============================] - 116s 19ms/step - loss: 0.8172 - acc: 0.7616 - val_loss: 1.4713 - val_acc: 0.6753\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.65129 to 0.67528, saving model to best_model.h5\n",
            "Epoch 5/50\n",
            "6141/6141 [==============================] - 115s 19ms/step - loss: 0.5595 - acc: 0.8295 - val_loss: 1.5574 - val_acc: 0.6568\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67528\n",
            "Epoch 6/50\n",
            "6141/6141 [==============================] - 116s 19ms/step - loss: 0.4123 - acc: 0.8771 - val_loss: 1.6593 - val_acc: 0.6753\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67528\n",
            "Epoch 7/50\n",
            "6141/6141 [==============================] - 114s 19ms/step - loss: 0.3377 - acc: 0.8999 - val_loss: 1.7905 - val_acc: 0.6476\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.67528\n",
            "Epoch 8/50\n",
            "6141/6141 [==============================] - 116s 19ms/step - loss: 0.2437 - acc: 0.9205 - val_loss: 1.7451 - val_acc: 0.6854\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.67528 to 0.68542, saving model to best_model.h5\n",
            "Epoch 9/50\n",
            "6141/6141 [==============================] - 114s 18ms/step - loss: 0.2194 - acc: 0.9282 - val_loss: 1.7621 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.68542\n",
            "Epoch 10/50\n",
            "6141/6141 [==============================] - 113s 18ms/step - loss: 0.2071 - acc: 0.9310 - val_loss: 1.7675 - val_acc: 0.6863\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.68542 to 0.68635, saving model to best_model.h5\n",
            "Epoch 11/50\n",
            "6141/6141 [==============================] - 114s 18ms/step - loss: 0.1994 - acc: 0.9339 - val_loss: 1.7713 - val_acc: 0.6891\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.68635 to 0.68911, saving model to best_model.h5\n",
            "Epoch 12/50\n",
            "6141/6141 [==============================] - 113s 18ms/step - loss: 0.1974 - acc: 0.9334 - val_loss: 1.7731 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.68911\n",
            "Epoch 13/50\n",
            "6141/6141 [==============================] - 115s 19ms/step - loss: 0.1933 - acc: 0.9349 - val_loss: 1.7795 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.68911\n",
            "Epoch 14/50\n",
            "6141/6141 [==============================] - 115s 19ms/step - loss: 0.1983 - acc: 0.9334 - val_loss: 1.7801 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.68911\n",
            "Epoch 15/50\n",
            "6141/6141 [==============================] - 114s 19ms/step - loss: 0.1936 - acc: 0.9357 - val_loss: 1.7802 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.68911\n",
            "Epoch 16/50\n",
            "6141/6141 [==============================] - 116s 19ms/step - loss: 0.1960 - acc: 0.9305 - val_loss: 1.7807 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.68911\n",
            "Epoch 17/50\n",
            "6141/6141 [==============================] - 115s 19ms/step - loss: 0.1971 - acc: 0.9334 - val_loss: 1.7807 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.68911\n",
            "Epoch 18/50\n",
            "6141/6141 [==============================] - 115s 19ms/step - loss: 0.1944 - acc: 0.9332 - val_loss: 1.7808 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.68911\n",
            "Epoch 19/50\n",
            "6141/6141 [==============================] - 119s 19ms/step - loss: 0.1903 - acc: 0.9365 - val_loss: 1.7809 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.68911\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLFxUza2Qy_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d02bea59-c63e-4634-cf9c-28cb8de1584a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 150, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 150, 256)          234496    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 150, 128)          32896     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 150, 52)           6708      \n",
            "=================================================================\n",
            "Total params: 1,274,100\n",
            "Trainable params: 1,274,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0l5yOuwQzD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bc35feb5-5633-4d27-8ceb-6251f6e77164"
      },
      "source": [
        "history = model.fit(X_train, y_train_keras,\n",
        "          nb_epoch=10, batch_size=32)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 2.6111 - acc: 0.4831\n",
            "Epoch 2/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 2.3042 - acc: 0.4995\n",
            "Epoch 3/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 2.1151 - acc: 0.5194\n",
            "Epoch 4/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.9403 - acc: 0.5434\n",
            "Epoch 5/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.7509 - acc: 0.5780\n",
            "Epoch 6/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.5949 - acc: 0.5989\n",
            "Epoch 7/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.4494 - acc: 0.6334\n",
            "Epoch 8/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.3151 - acc: 0.6598\n",
            "Epoch 9/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.2237 - acc: 0.6779\n",
            "Epoch 10/10\n",
            "4877/4877 [==============================] - 29s 6ms/step - loss: 1.0958 - acc: 0.7119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p41sGw6sNQvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdqGF2whNQ0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwOPVAHOiAEd",
        "colab_type": "code",
        "outputId": "b7f42bd8-eb4b-4e46-aa74-5b97b12e78dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train_keras)\n",
        "y_test_cate = to_categorical(y_valid_keras)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train_keras = x_train_keras.astype(str)\n",
        "x_valid_keras = x_valid_keras.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(list(x_train_keras))\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq_keras  = tokenizer.texts_to_sequences(x_train_keras) \n",
        "x_val_seq_keras = tokenizer.texts_to_sequences(x_valid_keras)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq_keras  = pad_sequences(x_tr_seq_keras, maxlen=100,padding='post')\n",
        "x_val_seq_keras = pad_sequences(x_val_seq_keras, maxlen=100,padding='post')\n",
        "\n",
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4335, 52, 2)\n",
            "2872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpnIQjGKisOB",
        "colab_type": "code",
        "outputId": "d3824b88-bc0c-4630-d52d-15408b6a910f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "print(x_train_keras[24])\n",
        "print(x_tr_seq_keras[24])\n",
        "print(x_train_keras[52])\n",
        "print(x_tr_seq_keras[52])\n",
        "print(x_tr_seq_keras[24])\n",
        "print(x_tr_seq_keras[25])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "password reset password reset\n",
            "[148   5 858   5 126 405  11   9 248 109   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "outlook received\n",
            "[159 227   6 159 227   6   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[148   5 858   5 126 405  11   9 248 109   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[374   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qihg8vN3dN9X",
        "colab_type": "code",
        "outputId": "3430626a-af87-429d-cca6-885241505520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#from keras.layers.embeddings import Embedding\n",
        "#from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "#embedding layer\n",
        "model.add(Embedding(10000,100,input_length=100,trainable=True)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "#model.add(Dense(256,activation='relu'))  \n",
        "model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(52,activation='softmax'))  \n",
        "\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-15, decay=0.0), loss='categorical_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "\n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-ffa2597af1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#lstm layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    172\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    173\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <keras.layers.embeddings.Embedding object at 0x7f152e94ed30>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw3a_koWeA4o",
        "colab_type": "code",
        "outputId": "37300cbf-a019-41ef-e426-89a43035f235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_tr_seq_keras,y_train_keras,batch_size=32,epochs=100,validation_data=(x_val_seq_keras,y_valid_keras),verbose=1,callbacks=[es,mc])\n",
        "#model.fit(x_tr_seq_fast,y_train_fast,batch_size=32,epochs=10,validation_data=(x_val_seq_fast,y_valid_fast),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 2.4157 - acc: 0.4960\n",
            "Epoch 00001: val_acc improved from -inf to 0.48339, saving model to best_model.h5\n",
            "136/136 [==============================] - 36s 266ms/step - loss: 2.4157 - acc: 0.4960 - val_loss: 2.3297 - val_acc: 0.4834\n",
            "Epoch 2/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 1.9713 - acc: 0.5412\n",
            "Epoch 00002: val_acc improved from 0.48339 to 0.50830, saving model to best_model.h5\n",
            "136/136 [==============================] - 40s 294ms/step - loss: 1.9713 - acc: 0.5412 - val_loss: 2.1687 - val_acc: 0.5083\n",
            "Epoch 3/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 1.5999 - acc: 0.5991\n",
            "Epoch 00003: val_acc improved from 0.50830 to 0.52214, saving model to best_model.h5\n",
            "136/136 [==============================] - 36s 262ms/step - loss: 1.5999 - acc: 0.5991 - val_loss: 2.0375 - val_acc: 0.5221\n",
            "Epoch 4/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 1.2820 - acc: 0.6713\n",
            "Epoch 00004: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 261ms/step - loss: 1.2820 - acc: 0.6713 - val_loss: 2.1183 - val_acc: 0.5166\n",
            "Epoch 5/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.9887 - acc: 0.7375\n",
            "Epoch 00005: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 261ms/step - loss: 0.9887 - acc: 0.7375 - val_loss: 2.2623 - val_acc: 0.5046\n",
            "Epoch 6/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.7755 - acc: 0.7917\n",
            "Epoch 00006: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 261ms/step - loss: 0.7755 - acc: 0.7917 - val_loss: 2.4354 - val_acc: 0.5203\n",
            "Epoch 7/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.6032 - acc: 0.8311\n",
            "Epoch 00007: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 260ms/step - loss: 0.6032 - acc: 0.8311 - val_loss: 2.7238 - val_acc: 0.5185\n",
            "Epoch 8/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.4821 - acc: 0.8676\n",
            "Epoch 00008: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 261ms/step - loss: 0.4821 - acc: 0.8676 - val_loss: 2.9650 - val_acc: 0.5120\n",
            "Epoch 9/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.3872 - acc: 0.8879\n",
            "Epoch 00009: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 261ms/step - loss: 0.3872 - acc: 0.8879 - val_loss: 3.4132 - val_acc: 0.4963\n",
            "Epoch 10/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.3082 - acc: 0.9114\n",
            "Epoch 00010: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 263ms/step - loss: 0.3082 - acc: 0.9114 - val_loss: 3.7910 - val_acc: 0.5138\n",
            "Epoch 11/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.2531 - acc: 0.9269\n",
            "Epoch 00011: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 261ms/step - loss: 0.2531 - acc: 0.9269 - val_loss: 3.9339 - val_acc: 0.5083\n",
            "Epoch 12/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.2199 - acc: 0.9389\n",
            "Epoch 00012: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 261ms/step - loss: 0.2199 - acc: 0.9389 - val_loss: 4.0262 - val_acc: 0.5055\n",
            "Epoch 13/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1744 - acc: 0.9497\n",
            "Epoch 00013: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 261ms/step - loss: 0.1744 - acc: 0.9497 - val_loss: 4.4578 - val_acc: 0.5074\n",
            "Epoch 14/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1523 - acc: 0.9578\n",
            "Epoch 00014: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 35s 261ms/step - loss: 0.1523 - acc: 0.9578 - val_loss: 4.5440 - val_acc: 0.5046\n",
            "Epoch 15/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1477 - acc: 0.9532\n",
            "Epoch 00015: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 262ms/step - loss: 0.1477 - acc: 0.9532 - val_loss: 4.8083 - val_acc: 0.4806\n",
            "Epoch 16/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.9642\n",
            "Epoch 00016: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 263ms/step - loss: 0.1219 - acc: 0.9642 - val_loss: 4.8634 - val_acc: 0.5018\n",
            "Epoch 17/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1053 - acc: 0.9693\n",
            "Epoch 00017: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 263ms/step - loss: 0.1053 - acc: 0.9693 - val_loss: 5.0970 - val_acc: 0.4954\n",
            "Epoch 18/100\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.0800 - acc: 0.9785\n",
            "Epoch 00018: val_acc did not improve from 0.52214\n",
            "136/136 [==============================] - 36s 262ms/step - loss: 0.0800 - acc: 0.9785 - val_loss: 5.3232 - val_acc: 0.4963\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c3d03f630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ZT0bdsxLna",
        "colab_type": "code",
        "outputId": "efaeeeb0-47a9-4fcc-ae4a-5a05e6789166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#loading best model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,val_acc = model.evaluate(x_val_seq_keras,y_valid_keras, batch_size=100)\n",
        "print(val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 2s 158ms/step - loss: 2.0375 - acc: 0.5221\n",
            "0.5221402049064636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHXt6PeuVtOy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fnYqywn5s4N",
        "colab_type": "code",
        "outputId": "9cf36d8c-516e-48ff-a2d6-aefb2432a446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_cate = to_categorical(y_train_keras)\n",
        "y_test_cate = to_categorical(y_valid_keras)\n",
        "print(y_train_cate.shape)\n",
        "\n",
        "x_train_keras = x_train_keras.astype(str)\n",
        "x_valid_keras = x_valid_keras.astype(str)\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=10000,char_level=False)\n",
        "\n",
        "#preparing vocabulary\n",
        "tokenizer.fit_on_texts(list(x_train_keras))\n",
        "\n",
        "#converting text into integer sequences\n",
        "x_tr_seq_keras  = tokenizer.texts_to_sequences(x_train_keras) \n",
        "x_val_seq_keras = tokenizer.texts_to_sequences(x_valid_keras)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "x_tr_seq_keras_pre  = pad_sequences(x_tr_seq_keras, maxlen=100)\n",
        "x_val_seq_keras_pre = pad_sequences(x_val_seq_keras, maxlen=100)\n",
        "\n",
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4335, 52, 2)\n",
            "2872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsF40AfN_LEV",
        "colab_type": "code",
        "outputId": "61276c16-59af-4660-eb8e-89f749792832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "print(x_train_keras[24])\n",
        "print(x_tr_seq_keras_pre[24])\n",
        "print(x_train_keras[52])\n",
        "print(x_tr_seq_keras_pre[52])\n",
        "print(x_tr_seq_keras_pre[24])\n",
        "print(x_tr_seq_keras_pre[25])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "password reset password reset\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            " 148   5 858   5 126 405  11   9 248 109]\n",
            "outlook received\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0 159 227   6 159 227   6]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            " 148   5 858   5 126 405  11   9 248 109]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0 374]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K9KHvkbOu1b",
        "colab_type": "code",
        "outputId": "01ab30f1-90e7-48b9-f1f4-1920a5036ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "#from keras.layers.embeddings import Embedding\n",
        "#from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "#embedding layer\n",
        "model.add(Embedding(size_of_vocabulary,100,input_length=100,trainable=True)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.2)))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "#model.add(Dense(256,activation='relu'))  \n",
        "model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dense(52,activation='softmax'))  \n",
        "\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-15, decay=0.0), loss='categorical_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', baseline=None, restore_best_weights=False)  \n",
        "\n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 100, 100)          287200    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 100, 256)          234496    \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 25600)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               3276928   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 52)                6708      \n",
            "=================================================================\n",
            "Total params: 3,805,332\n",
            "Trainable params: 3,805,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vONejLPVPASs",
        "colab_type": "code",
        "outputId": "5abb98a1-040a-42c7-d80e-815953dd8d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "model.fit(x_tr_seq_keras_pre,y_train_keras,batch_size=32,epochs=10,validation_data=(x_val_seq_keras_pre,y_valid_keras),verbose=1,callbacks=[es,mc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.7309 - acc: 0.8030\n",
            "Epoch 00001: val_acc improved from 0.52583 to 0.53321, saving model to best_model.h5\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.7309 - acc: 0.8030 - val_loss: 2.6639 - val_acc: 0.5332\n",
            "Epoch 2/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.5690 - acc: 0.8464\n",
            "Epoch 00002: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.5690 - acc: 0.8464 - val_loss: 2.7841 - val_acc: 0.5212\n",
            "Epoch 3/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.4614 - acc: 0.8764\n",
            "Epoch 00003: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 263ms/step - loss: 0.4614 - acc: 0.8764 - val_loss: 3.0761 - val_acc: 0.5129\n",
            "Epoch 4/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.3692 - acc: 0.9020\n",
            "Epoch 00004: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.3692 - acc: 0.9020 - val_loss: 3.5155 - val_acc: 0.5148\n",
            "Epoch 5/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.3103 - acc: 0.9181\n",
            "Epoch 00005: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.3103 - acc: 0.9181 - val_loss: 3.5345 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.2779 - acc: 0.9195\n",
            "Epoch 00006: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.2779 - acc: 0.9195 - val_loss: 3.8036 - val_acc: 0.5129\n",
            "Epoch 7/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.2366 - acc: 0.9343\n",
            "Epoch 00007: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.2366 - acc: 0.9343 - val_loss: 3.9110 - val_acc: 0.5055\n",
            "Epoch 8/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1988 - acc: 0.9442\n",
            "Epoch 00008: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 264ms/step - loss: 0.1988 - acc: 0.9442 - val_loss: 4.2077 - val_acc: 0.5101\n",
            "Epoch 9/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1577 - acc: 0.9539\n",
            "Epoch 00009: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 265ms/step - loss: 0.1577 - acc: 0.9539 - val_loss: 4.4064 - val_acc: 0.5074\n",
            "Epoch 10/10\n",
            "136/136 [==============================] - ETA: 0s - loss: 0.1325 - acc: 0.9633\n",
            "Epoch 00010: val_acc did not improve from 0.53321\n",
            "136/136 [==============================] - 36s 265ms/step - loss: 0.1325 - acc: 0.9633 - val_loss: 4.5083 - val_acc: 0.5055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c3ed69358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxvQW3R_PmhE",
        "colab_type": "code",
        "outputId": "247691de-6c18-43d4-d4aa-c69236d235de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#loading best model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,val_acc = model.evaluate(x_val_seq_keras_pre,y_valid_keras, batch_size=100)\n",
        "print(val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 2s 157ms/step - loss: 2.6639 - acc: 0.5332\n",
            "0.5332103371620178\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}